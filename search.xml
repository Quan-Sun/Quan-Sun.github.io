<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>7 problems of backtracking algorithm</title>
    <url>/2019/12/22/7-problems-of-backtracking-algorithm/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p> A summary for 7 “backtracking” problems in Leetcode.  This kind of problems can be solved in a template. It’s easy to find the pattern as following.</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nums: a vector of numbers that you have to traverse</span></span><br><span class="line"><span class="comment">// ans: a vector to record final answer</span></span><br><span class="line"><span class="comment">// path: a vector to record traversing numbers</span></span><br><span class="line"><span class="comment">// start: a start point taht you do DFS in 'nums'</span></span><br><span class="line"><span class="comment">// target: a target of final answer, i.e.the numbers sums to target</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="keyword">int</span> start, <span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (target==<span class="number">0</span>) &#123; <span class="comment">// the condition of push path into ans</span></span><br><span class="line">            ans.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (target &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// 'backtarcking - kits': push_back; DFS; pop_back.</span></span><br><span class="line">                <span class="comment">// you will find the next 3 lines of code in all 'backtracking' problems</span></span><br><span class="line">                path.push_back(nums[i]);</span><br><span class="line">                dfs(nums, ans, i, target-nums[i], path);</span><br><span class="line">                path.pop_back();                </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><a id="more"></a>


<h4 id="17-Letter-Combinations-of-a-Phone-Number"><a href="#17-Letter-Combinations-of-a-Phone-Number" class="headerlink" title="17.Letter Combinations of a Phone Number"></a>17.Letter Combinations of a Phone Number</h4><p>Given a string containing digits from <code>2-9</code> inclusive, return all possible letter combinations that the number could represent.</p>
<p>A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters.</p>
<p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Telephone-keypad2.svg/200px-Telephone-keypad2.svg.png" alt></p>
<p><strong>Example:</strong></p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Input:</span> <span class="string">"23"</span></span><br><span class="line"><span class="symbol">Output:</span> [<span class="string">"ad"</span>, <span class="string">"ae"</span>, <span class="string">"af"</span>, <span class="string">"bd"</span>, <span class="string">"be"</span>, <span class="string">"bf"</span>, <span class="string">"cd"</span>, <span class="string">"ce"</span>, <span class="string">"cf"</span>].</span><br></pre></td></tr></table></figure>

<p><strong>Note:</strong></p>
<p>Although the above answer is in lexicographical order, your answer could be in any order you want.</p>
<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; letterCombinations(<span class="built_in">string</span> digits) &#123;</span><br><span class="line">        <span class="keyword">if</span> (digits.empty()) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt; d(<span class="number">10</span>);</span><br><span class="line">        d[<span class="number">0</span>] = &#123;<span class="string">' '</span>&#125;;</span><br><span class="line">        d[<span class="number">1</span>] = &#123;&#125;;</span><br><span class="line">        d[<span class="number">2</span>] = &#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>&#125;;</span><br><span class="line">        d[<span class="number">3</span>] = &#123;<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>&#125;;</span><br><span class="line">        d[<span class="number">4</span>] = &#123;<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>&#125;;</span><br><span class="line">        d[<span class="number">5</span>] = &#123;<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>&#125;;</span><br><span class="line">        d[<span class="number">6</span>] = &#123;<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>&#125;;</span><br><span class="line">        d[<span class="number">7</span>] = &#123;<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>&#125;;</span><br><span class="line">        d[<span class="number">8</span>] = &#123;<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>&#125;;</span><br><span class="line">        d[<span class="number">9</span>] = &#123;<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>&#125;;</span><br><span class="line">        <span class="built_in">string</span> cur;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ans;</span><br><span class="line">        dfs(digits, d, <span class="number">0</span>, cur, ans);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; digits,</span></span></span><br><span class="line"><span class="function"><span class="params">             <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt;&amp; d,</span></span></span><br><span class="line"><span class="function"><span class="params">             <span class="keyword">int</span> l, <span class="built_in">string</span>&amp; cur, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; ans)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (l == digits.length()) &#123;</span><br><span class="line">            ans.push_back(cur);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">char</span> c : d[digits[l] - <span class="string">'0'</span>]) &#123;</span><br><span class="line">            cur.push_back(c);</span><br><span class="line">            dfs(digits, d, l+<span class="number">1</span>, cur, ans);</span><br><span class="line">            cur.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="39-Combination-Sum"><a href="#39-Combination-Sum" class="headerlink" title="39.Combination Sum"></a>39.Combination Sum</h4><p>Given a <strong>set</strong> of candidate numbers (<code>candidates</code>) <strong>(without duplicates)</strong> and a target number (<code>target</code>), find all unique combinations in <code>candidates</code> where the candidate numbers sums to <code>target</code>.</p>
<p>The <strong>same</strong> repeated number may be chosen from <code>candidates</code> unlimited number of times.</p>
<p><strong>Note:</strong></p>
<ul>
<li>All numbers (including <code>target</code>) will be positive integers.</li>
<li>The solution set must not contain duplicate combinations.</li>
</ul>
<p><strong>Example 1:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: candidates = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">7</span>], target = <span class="number">7</span>,</span><br><span class="line">A solution <span class="keyword">set</span> <span class="keyword">is</span>:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">7</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Example 2:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: candidates = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>], target = <span class="number">8</span>,</span><br><span class="line">A solution <span class="keyword">set</span> <span class="keyword">is</span>:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">3</span>,<span class="number">5</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> (candidates.empty()) <span class="keyword">return</span> ans;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path;</span><br><span class="line">        dfs(candidates, ans, <span class="number">0</span>, target, path);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="keyword">int</span> start, <span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (target==<span class="number">0</span>) &#123;</span><br><span class="line">            ans.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; candidates.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (target &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                path.push_back(candidates[i]);</span><br><span class="line">                dfs(candidates, ans, i, target-candidates[i], path);</span><br><span class="line">                path.pop_back();</span><br><span class="line">                </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="40-Combination-Sum-II"><a href="#40-Combination-Sum-II" class="headerlink" title="40.Combination Sum II"></a>40.Combination Sum II</h4><p>Given a collection of candidate numbers (<code>candidates</code>) and a target number (<code>target</code>), find all unique combinations in <code>candidates</code> where the candidate numbers sums to <code>target</code>.</p>
<p>Each number in <code>candidates</code> may only be used <strong>once</strong> in the combination.</p>
<p><strong>Note:</strong></p>
<ul>
<li>All numbers (including <code>target</code>) will be positive integers.</li>
<li>The solution set must not contain duplicate combinations.</li>
</ul>
<p><strong>Example 1:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: candidates = [<span class="number">10</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">5</span>], target = <span class="number">8</span>,</span><br><span class="line">A solution <span class="keyword">set</span> <span class="keyword">is</span>:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">1</span>, <span class="number">7</span>],</span><br><span class="line">  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">  [<span class="number">2</span>, <span class="number">6</span>],</span><br><span class="line">  [<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Example 2:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: candidates = [<span class="number">2</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>], target = <span class="number">5</span>,</span><br><span class="line">A solution <span class="keyword">set</span> <span class="keyword">is</span>:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">5</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum2(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> (candidates.empty()) <span class="keyword">return</span> ans;</span><br><span class="line">        sort(candidates.<span class="built_in">begin</span>(), candidates.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path;</span><br><span class="line">        dfs(candidates, ans, <span class="number">0</span>, target, path);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="keyword">int</span> start, <span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (target &lt; <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span> (target == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// auto ret = find(ans.begin(),ans.end(),path);</span></span><br><span class="line">            <span class="comment">// if (ret == ans.end()) </span></span><br><span class="line">                ans.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; candidates.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &gt; start &amp;&amp; candidates[i] == candidates[i<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            path.push_back(candidates[i]);</span><br><span class="line">            dfs(candidates, ans, i+<span class="number">1</span>, target-candidates[i], path);</span><br><span class="line">            path.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="77-Combinations"><a href="#77-Combinations" class="headerlink" title="77.Combinations"></a>77.Combinations</h4><p>Given two integers <em>n</em> and <em>k</em>, return all possible combinations of <em>k</em> numbers out of 1 … <em>n</em>.</p>
<p><strong>Example:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: n = <span class="number">4</span>, k = <span class="number">2</span></span><br><span class="line">Output:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">2</span>,<span class="number">4</span>],</span><br><span class="line">  [<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">4</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combine(<span class="keyword">int</span> n, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> (n &lt; k) <span class="keyword">return</span> ans;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path(<span class="number">0</span>, k);</span><br><span class="line">        dfs(ans, path, <span class="number">0</span>, <span class="number">0</span>, n, k);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path, <span class="keyword">int</span> start, <span class="keyword">int</span> num, <span class="keyword">int</span> n, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (num == k) &#123;</span><br><span class="line">            ans.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; n; ++i) &#123;</span><br><span class="line">            path.push_back(i + <span class="number">1</span>);</span><br><span class="line">            dfs(ans, path, i+<span class="number">1</span>, num+<span class="number">1</span>, n, k);</span><br><span class="line">            path.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="78-Subsets"><a href="#78-Subsets" class="headerlink" title="78.Subsets"></a>78.Subsets</h4><p>Given a set of <strong>distinct</strong> integers, <em>nums</em>, return all possible subsets (the power set).</p>
<p><strong>Note:</strong> The solution set must not contain duplicate subsets.</p>
<p><strong>Example:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">Output:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>],</span><br><span class="line">  [<span class="number">2</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">  []</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; subsets(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> (nums.empty()) <span class="keyword">return</span> ans;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path;</span><br><span class="line">        dfs(ans, path, <span class="number">0</span>, nums);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path, <span class="keyword">int</span> start, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        ans.push_back(path);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            path.push_back(nums[i]);</span><br><span class="line">            dfs(ans, path, i+<span class="number">1</span>, nums);</span><br><span class="line">            path.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="90-Subsets-II"><a href="#90-Subsets-II" class="headerlink" title="90.Subsets II"></a>90.Subsets II</h4><p>Given a collection of integers that might contain duplicates, <strong><em>nums\</em></strong>, return all possible subsets (the power set).</p>
<p><strong>Note:</strong> The solution set must not contain duplicate subsets.</p>
<p><strong>Example:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line">Output:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">2</span>],</span><br><span class="line">  [<span class="number">1</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">  []</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; subsetsWithDup(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> (nums.empty()) <span class="keyword">return</span> ans;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path;</span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">        dfs(ans, path, <span class="number">0</span>, nums);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path, <span class="keyword">int</span> start, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;   </span><br><span class="line">        ans.push_back(path);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i == start || nums[i] != nums[i - <span class="number">1</span>]) &#123; </span><br><span class="line">                path.push_back(nums[i]);</span><br><span class="line">                dfs(ans, path, i+<span class="number">1</span>, nums);</span><br><span class="line">                path.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="216-Combination-Sum-III"><a href="#216-Combination-Sum-III" class="headerlink" title="216.Combination Sum III"></a>216.Combination Sum III</h4><p>Find all possible combinations of <strong><em>k</em></strong> numbers that add up to a number <strong><em>n</em></strong>, given that only numbers from 1 to 9 can be used and each combination should be a unique set of numbers.</p>
<p><strong>Note:</strong></p>
<ul>
<li>All numbers will be positive integers.</li>
<li>The solution set must not contain duplicate combinations.</li>
</ul>
<p><strong>Example 1:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: k = <span class="number">3</span>, n = <span class="number">7</span></span><br><span class="line">Output: [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>

<p><strong>Example 2:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Input: k = <span class="number">3</span>, n = <span class="number">9</span></span><br><span class="line">Output: [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">6</span>], [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>

<p><strong>Solution:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum3(<span class="keyword">int</span> k, <span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line">        <span class="keyword">if</span> ( k == <span class="number">0</span> || n == <span class="number">0</span>) <span class="keyword">return</span> ans;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; path;</span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">        dfs(ans, path, <span class="number">1</span>, sum, k, n);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; ans, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; path, <span class="keyword">int</span> start, <span class="keyword">int</span> sum, <span class="keyword">int</span> k, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (sum &gt; n) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span> (sum == n &amp;&amp; path.<span class="built_in">size</span>() == k)&#123;</span><br><span class="line">            ans.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt;= <span class="number">9</span>; ++i) &#123;</span><br><span class="line">            path.push_back(i);</span><br><span class="line">            sum += i;</span><br><span class="line">            dfs(ans, path, i+<span class="number">1</span>, sum, k, n);</span><br><span class="line">            sum -= i;</span><br><span class="line">            path.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>backtracking</tag>
      </tags>
  </entry>
  <entry>
    <title>ResNet</title>
    <url>/2019/12/17/ResNet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>paper地址: <a href="https://arxiv.org/pdf/1512.03385v1.pdf" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>2015年的ILSVRC冠军是微软的ResNet，152层的ResNet在深度和错误率上都创造了记录。可以说ResNet的出现使得Deep Learning真正的进入了”Deep”的时代，其中所提出的残差学习对之后深度学习的发展产生了深远的影响。</p><p>ResNet到底解决的是什么问题？之前看到有些文章说它解决了梯度消失的问题，但是，这很明显是错误的。ResNet的paper中，作者直接指出了梯度消失的问题在BN提出之后基本上已经得到了解决，而ResNet解决的是degradation的问题。所谓degradation就是，随着网络层数的增加，网络的正确率会饱和，然后迅速退化。</p><a id="more"></a>


<blockquote>
<p>Driven by the significance of depth, a question arises: Is learning better networks as easy as stacking more layers? <strong>An obstacle to answering this question was the notorious problem of vanishing/exploding gradients, which hamper convergence from the beginning. This problem, however, has been largely addressed by normalized initialization and intermediate normalization layers</strong>, which enable networks with tens of layers to start converging for stochastic gradient descent (SGD) with backpropagation. <strong>When deeper networks are able to start converging, a degradation problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly</strong>. Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in and thoroughly verified by our experiments.</p>
</blockquote>
<p>所以，网络变深之后会出现两个问题。第一个问题就是梯度消失、爆炸，这个问题在BN出现后被顺利解决。BN层能对各层的输出做归一化，这样梯度在反向层层传递后仍能保持大小稳定，不会出现过小或过大的情况。加入BN后再加大深度是不是就很容易收敛了呢？答案仍是否定的。因为第二个问题，degradation problem，的存在。层数到达一定程度时准确率就会饱和，然后迅速下降，而且这种下降既不是梯度消失引起的，也不是过拟合造成的，而是由于网络过于复杂，以至于光靠不加约束的训练很难达到理想的错误率。degradation problem不是网络结构本身的问题，而是现有的训练方式不够理想造成的。当前广泛使用的训练方法，无论是SGD，还是AdaGrad，还是RMSProp，都无法在网络深度变大后达到理论上最优的收敛结果。</p>
<blockquote>
<p>神经网络越来越深的时候，反向传递回来的梯度之间的相关性会越来越差，最后接近白噪声。因为我们知道图像是具备局部相关性的，那么可以认为梯度也应该具备类似的相关性，这样更新的梯度才有意义。如果梯度接近白噪声，那梯度更新可能根本就是在做随机扰动。即使BN过后梯度的模稳定在了正常范围内，但梯度的相关性实际上是随着层数增加持续衰减的。而经过证明，ResNet可以有效减少这种衰减。</p>
</blockquote>
<p>对于这个问题还有另外两种理解:</p>
<ul>
<li>Feature Pyramid Network中提出的，跳连接相加可以实现不同分辨率特征的组合，因为浅层容易有高分辨率但是低级语义的特征，而深层的特征有高级语义，但分辨率就很低了。</li>
<li>引入跳连接实际上让模型自身有了更加“灵活”的结构，即在训练过程本身，模型可以选择在每一个部分是“更多进行卷积与非线性变换”还是“更多倾向于什么都不做”，抑或是将两者结合。</li>
</ul>
<p>可以证明只要有理想的训练方式，更深的网络肯定会比较浅的网络效果要好。证明过程也很简单：假设在一个网络A的后面再添加几层网络形成新的网络B，如果增加的层只是对A的输出做了恒等映射(identity mapping)，即A的输出经过新增的层变成B的输出后没有发生变化，这样网络A和网络B的错误率就是相等的，也就证明了加深后的网络不会比加深前的网络效果差。</p>
<blockquote>
<p>There exists a solution by construction to the deeper model: the added layers are identity mapping, and the other layers are copied from the learned shallower model. The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart.</p>
</blockquote>
<p>作者提出了残差结构实现了上述的恒等映射。整个模块除了正常的卷积层输出外，还有一个分支把输入直接连到输出上，该输出和卷积的输出做算术相加得到最终的输出，用公式表达就是$H(x)=F(x)+x$，$x$是输入，$F(x)$是卷积分支的输出，$H(x)$是整个结构的输出。可以证明如果$F(x)$分支中所有参数都是0，$H(x)$就是个恒等映射。残差结构是人为制造的恒等映射，可以让整个结构朝着恒等映射的方向去收敛，确保最终的错误率不会因为深度的变大而越来越差。如果一个网络通过简单的手工设置参数值就能达到想要的结果，那这种结构就很容易通过训练来收敛到该结果，这是一条设计复杂的网络时屡试不爽的规则。</p>
<p><img src="/2019/12/17/ResNet/image-20191217211546271.png" alt="残差结构"></p>
<p>$F$是求和前网络映射，$H$是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是$F’(5)=5.1$，引入残差后是$H(5)=5.1$, $H(5)=F(5)+5$, $F(5)=0.1$。这里的$F’$和$F$都表示网络参数映射，引入残差后的映射对输出的变化更敏感。比如输出从5.1变到5.2，映射$F’$的输出增加了1/51=2%​，而对于残差结构,输出从5.1到5.2，映射$F$是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化。</p>
<p>作者在ImageNet上证明了ResNet的有效性。比较了相同层数的ResNet结构和传统结构的训练效果。下图左侧是一个传统结构的VGG-19网络(每个卷积后都跟了BN)，中间是传统结构的34层网络(每个卷积后都跟了BN)，右侧是34层的ResNet(实线表示直连，虚线表示用1x1卷积进行了维度变化，匹配输入输出的特征数)。</p>
<p><img src="/2019/12/17/ResNet/ResNet.png" alt="三种网络结构对比"></p>
<p>这几种网络训练后的结果如下图所示，左侧的数据看出传统结构的34层网络(红线)要比VGG-19(蓝绿色线)的错误率高，由于每层都加了BN结构，所以错误高并不是由于层级增大后梯度消失引起的，而是degradation problem造成；右侧的ResNet结构可以看到34层网络(红线)要比18层网络(蓝绿色线)错误率低，这是因为ResNet结构已经克服了degradation problem。此外右侧ResNet 18层网络最后的错误率和左侧传统18层网络的错误率相近，这是因为18层网络较为简单，即使不用ResNet结构也可以收敛到比较理想的结果。</p>
<p><img src="/2019/12/17/ResNet/image-20191217212204960.png" alt="ImageNet上的结果"></p>
<p>像上图左侧那样的ResNet结构只是用于较浅的ResNet网络，如果网络层数较多，靠近网络输出端的维度就会很大,仍使用左侧的结构会造成计算量极大。对较深的网络我们都使用右侧的bottleneck结构，即先用一个1x1卷积进行降维，然后3x3卷积，最后用1x1升维恢复原有的维度。</p>
<p><img src="/2019/12/17/ResNet/image-20191217212350482.png" alt="bottleneck"></p>
<p>作者提出并比较了三种identity shortcuts，</p>
<blockquote>
<p>(A) zero-padding shortcuts are used for increasing dimensions, and all shortcuts are parameter-free; (B) projection shortcuts are used for increasing dimensions, and other shortcuts are identity; and (C) all shortcuts are projections.</p>
</blockquote>
<p><img src="/2019/12/17/ResNet/image-20191217212901866.png" alt="三种identity shortcuts效果比较"></p>
<p>上图可以看出B比A好一点，这是因为A中的zero-padded dimensions并没有学习到残差。C又比B好一点，这是因为引入了更多的projection shortcuts导致额外的参数。但是，其实三种结构的效果相差不大，这就说明projection shortcuts并不是解决degradation问题的必须条件。所以，为了减少内存/时间复杂度和模型大小，作者并没有选择C，二十使用了B。Identity shortcuts对于不增加bottleneck结构的复杂度非常重要。</p>
<p>作者也构建了更深的ResNet网络，结构如下:</p>
<p><img src="/2019/12/17/ResNet/image-20191217212110649.png" alt="ImageNet上网络的结构"></p>
<p>下面贴上一个在知乎上看到的一个特别有意思的对于ResNet的思考。</p>
<p>最近在总结完成语义分割任务的轻量级神经网络时，看到了 MobileNet V2 中对于 ReLU 层的思考，于是我也回过头重新审视 ResNet 之所以 work 的本质原因。以下是一些个人的见解，如有错误，还望及时指正。</p>
<p>在谈及 ResNet 之前，我们先聊聊故事的背景。我们知道，在神经网络中，非线性激活层可以为模型引入了非线性，让模型具有更强的拟合能力。如果只是单纯的线性操作层的叠加，则完全可以等价为一个线性层，这就浪费了深度神经网络的一身好本领。所谓针无两头尖，那么非线性激活层会带来一些什么问题呢？我们以 ReLU 为例来进行说明，其他非线性激活层亦同理。</p>
<p>首先，最直观的，从实验中我们可以注意到一个事实：ReLU 会造成的低维数据的坍塌（collapse）。顾名思义，即是说，低维度的 feature 在通过 ReLU 的时候，这个 feature 会像塌方了一样，有一部分被毁掉了，或者说失去了。能恢复吗？能，但是基本无法百分百还原了。</p>
<p>具体表现出来就是：若是我们对一个 feature，先通过一个给定的变换规则 T，将它映射到它的 embedding space 中，再在该 embedding space 中，利用一个 ReLU 去处理该 feature，最后再把这个 feature 以同样的变换规则（逆方向）给映射回原始空间，我们会发现，这时，这个 feature 已经变得连亲妈都不认得了。</p>
<p><img src="/2019/12/17/ResNet/ReLu-mobileNet.png" alt="ReLu-mobileNet"></p>
<p>ReLU 这个东西，其实就是一个滤波器，只不过这个滤波器的作用域不是信号处理中的频域，而是特征域。那么滤波器又有什么作用呢？维度压缩，俗话说就是降维啦：如果我们有 $m$ 个 features 被送入 ReLU 层，过滤剩下 $n $个($n&lt;m$)，这不就是相当于对 features 的维度进行了压缩，使其从 $m$ 维变为 $n$维嘛。</p>
<p>那么，为什么低维数据流经非线性激活层会发生坍塌（信息丢失），而高维数据就不会呢？</p>
<p>打个简单但不严谨的比方：大家都有过年抢高铁票的经验吧？几个人（维度低）帮你抢一张票，肯定没有一群人（维度高）帮你抢一张票，成功的概率高啊。几个人里面，大概率全军覆没，没一个能帮上你忙的。而一群人里面，大概率总有那么一个手速惊人的单身青年，帮你抢到你心心念念的回家票。</p>
<p>在数据上也是一个道理，维度低的 feature，分布到 ReLU 的激活带上的概率小，因此经过后信息丢失严重，甚至可能完全丢失。而维度高的 feature，分布到 ReLU 的激活带上的概率大，虽然可能也会有信息的部分丢失，但是无伤大雅，大部分的信息仍然得以保留。所谓留得青山在，不愁没柴烧嘛。更何况被 ReLU 截杀的信息，可能只是一些无用游民（冗余信息）。</p>
<p>那么数据的坍塌，是个很严重的事吗？<br>那事儿可大了。如果把神经网络比作一个人的话，你这就是给它的某个部位的血管里，丢了个血栓。当信息无法流过 ReLU 时，该神经元的输出就会变为 0。而在反向传播的过程中，ReLU 对 0 值的梯度为 0，即发生了梯度消失，这将导致神经元的权重无法再通过梯度下降法进行更新，这种现象被称为特征退化。所以这个神经元相当于死掉了，丧失了学习能力。我们说，一旦神经元的输出陷入 0 值，就无法恢复了。<br>那么，我们应该怎么去规避数据的坍塌呢？非线性激活层到底是个什么样的东西？</p>
<p>其实，对于一个数据，利用非线性激活层对其进行激活，其实是从该数据的信息中提取出其潜在的稀疏性，但是这种提取的结果是否正确，就要分情况讨论了。</p>
<p>对于一个 $M$ 维的数据，我们可以将其看成是在 $M$ 维空间中的一个 $M$ 维流形（manifold）。而其中的有用信息，就是在该 $M$ 维空间中的一个子空间（子空间的维度记为 $N $维，$N&lt;=M$）中的一个 $N$ 维流形。非线性激活层相当于压缩了这个 $M$ 维空间的维度（还记得前面提过的维度压缩吗？）。若是该 M 维空间中的 M 维流形本来就不含有冗余信息($M=N$)，那么再对其进行维度压缩，必然导致信息的丢失。</p>
<p>而维度低的数据其实就是这么一种情况：其信息的冗余度高的可能性本来就低，如果强行对其进行非线性激活（维度压缩），则很有可能丢失掉有用信息，甚至丢失掉全部信息（输出为全 0）。</p>
<p>与非线性激活层不同的是，线性激活层并不压缩特征空间的维度。于是，我们得到了一条使用激活层的原则：对含有冗余信息的数据使用非线性激活（如 ReLU），对不含冗余信息的数据使用线性激活（如一些线性变换）。</p>
<p>两种类型的激活交替灵活使用，以同时兼顾非线性和信息的完整性。</p>
<p>由于冗余信息和非冗余信息所携带的有用信息是一样多的，因此在设计网络时，对内存消耗大的结构最好是用在非冗余信息上。</p>
<p>根据以上的原则设计出来的结构，聪明的你想到了什么？ResNet。不得不赞叹 Kaiming He 的天才，ResNet 这东西，描述起来固然简单，但是对它的理解每深一层，就会愈发发现它的精妙及优雅，从数学上解释起来非常简洁，非常令人信服，而且直切传统痛点。</p>
<p>ResNet 本质上就干了一件事：降低数据中信息的冗余度。具体说来，就是对非冗余信息采用了线性激活（通过 skip connection 获得无冗余的 identity 部分），然后对冗余信息采用了非线性激活（通过 ReLU 对 identity 之外的其余部分进行信息提取 / 过滤，提取出的有用信息即是残差）。</p>
<p>其中，提取 identity 这一步，就是 ResNet 思想的核心。从本文的观点来看，因为从数据中拿掉了非冗余信息的 identity 部分，会导致余下部分的信息冗余度变高。这就像从接近饱和的溶液中移走了一部分溶质，会使得剩下的溶液的饱和度降低，一个道理。</p>
<p>在这里也引用一下其他的一些观点，方便大家可以从一个更全面的角度去看这个问题：从特征复用的观点来看，提取 identity 部分，可以让网络不用再去学习一个 identity mapping（虽然是一样的东西，但是毕竟又要从头学起，讲真，换你来试试，这其实真的不容易学到），而是直接学习 residual。这就轻松愉快多了：站在巨人的肩膀上，做一点微小的工作什么的…</p>
<p>既然说了 ResNet 解决的痛点，也顺便多说几句它带来的好处：</p>
<p>由于 identity 之外的其余部分的信息冗余度较高，因此在对其使用 ReLU 进行非线性激活时，丢失的有用信息也会较少，ReLU 层输出为 0 的可能性也会较低。这就降低了在反向传播时 ReLU 的梯度消失的概率，从而便于网络的加深，以大大地发挥深度网络的潜能。</p>
<p>特征复用能加快模型的学习速度，因为参数的优化收敛得快（从 identity 的基础上直接学习残差，总比从头学习全部来得快）。</p>
<p>最后是两个小 tips：</p>
<ul>
<li>如果一个信息可以完整地流过一个非线性激活层，则这个非线性激活层对于这个信息而言，相当于仅仅作了一个线性激活。</li>
<li>解决由非线性激活导致的反向传播梯度消失的窍门，就是要提高进行非线性激活的信息的冗余度。</li>
</ul>
<p>Reference</p>
<p><a href="https://www.zhihu.com/question/64494691" target="_blank" rel="noopener">https://www.zhihu.com/question/64494691</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/60668529" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/60668529</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>Inception Network</title>
    <url>/2019/12/16/Inception-Network/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Inception networks也是深度学习的重要的奠基石。相比与之前说的AlexNet和VGG，它具有更深更宽更复杂的结构和更优异的表现，但是它的参数量甚至比AlexNet还要少好几倍。目前InceptionNet已经有了四个版本，分别是Inception v1、Inception v2、Inception v3和Inception v4,每一个版本都是对上一个版本的提升。</p><h2 id="Inception-v1"><a href="#Inception-v1" class="headerlink" title="Inception v1"></a>Inception v1</h2><p>paper地址: <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43022.pdf" target="_blank" rel="noopener">Going Deeper with Convolutions</a></p><p>Inception v1也被称为GoogleNet，它的网络结构是基于inception module构建的。</p><p>Inception module的结构如下图所示，</p><a id="more"></a>



<p><img src="/2019/12/16/Inception-Network/image-20191216203702435.png" alt="Inception module"></p>
<p>和之前的CNN网络不同，在inception module中，每一层的输入会经过4个并行的卷积层，也就是输出被拷贝成4份，同时提供给4个CNN层。在naive version中，4并行的结构分别为$1 \times 1$的卷积核，$3 \times 3$的卷积核，$5 \times 5$的卷积核和$3 \times 3$的max pooling。为了减少参数，在$3 \times 3$的卷积核和$5 \times 5$的卷积核之前以及$3 \times 3$的max pooling之后都加了一层$1 \times 1$的卷积核，这就是图(b)中的Inception module结构。</p>
<p>可以看到Inception module中大量的使用了$1 \times 1$的卷积核，相比输入，它可以输出更少的特征图，这样起到了降维的作用，可以明显减少参数量，因此称为瓶颈层。当在$3 \times 3$和$5 \times 5$等计算量巨大的卷积层之前使用时，这样的作用尤其明显。同时，$1 \times 1$，$3 \times 3$，$5 \times 5$的并行结构构成了更有效的卷积层，能够获取更复杂的特征。实际上，在对输入图像进行遍历扫描时，这种卷积层的组合结构相当于一个两层的神经网络，而不是简单的线性分类。所以，将Inception module看成是一个卷积层，它可以输出具有不同尺度复杂特征的特征图。</p>
<p>Inception module中，所有层的stride都是1，并且使用了SAME填充，因此，各个层的输出具有相同的尺寸，但深度可以不同。由于各个输出具有相同的尺寸，可以将其沿深度方向叠加，构成深度叠加层，也就是上图中的filter concatenation。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216205601390.png" alt="Inception v1结构"></p>
<p>GoogleNet有9个inception module组成，整个网络总共27层，最后一个inception module之后接了global average pooling。同时，在第三和第六个Inception module上，有两个辅助分类器。由平均池化层、卷积层、两个全连接层和一个softmax激活层组成。在训练时，其损失的30%添加到整体的损失中。目的是解决梯度消失问题以及归一化网络。实际上，作用并不大。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216211446484.png" alt="辅助分类器"></p>
<h2 id="Inception-v2-v3"><a href="#Inception-v2-v3" class="headerlink" title="Inception v2/v3"></a>Inception v2/v3</h2><p>paper地址: <a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p>
<h3 id="卷积核分解"><a href="#卷积核分解" class="headerlink" title="卷积核分解"></a>卷积核分解</h3><p>相较于Inception v1， Inception v2进一步改进了Inception module。在CNN网络中，临近的卷积核的输出具有很高的相关性，因此，在输出结果聚合前应该降维，得到相似的局部特征。而且Inception的全卷积网络的每个权重对应一个激活值的一次乘法操作。因此，任何计算开销的减少都将意味着训练参数的减少。这意味着在适当的因式分解下，我们可以得到更多解耦合的参数，这会加快我们的训练。同时，我们可以使用节约下来的计算和存储容量来增加卷积核数量，保持训练开销不变。</p>
<ul>
<li><p>将大尺寸的卷积核分解成多个小卷积核</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216212412062.png" alt="大尺寸卷积核分解"></p>
<p>之前在VGG中提到了同样的技术，2个$3 \times 3$的卷积核可以代替1个$5 \times 5$的卷积核，3个$3 \times 3$的卷积核可以代替1个$7 \times 7$的卷积核。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216212614620.png" alt="Inception v1中的Inception module"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216212639082.png" alt="使用卷积核分解后的Inception module"></p>
</li>
<li><p>将不对称的卷积核进行分解</p>
<p>可以使用非对称卷积。将$n \times n$的卷积分解成$1 \times n$和$n \times 1$卷积的串联。如下图，$3 \times 3$卷积可以分解为$1 \times 3$和$3 \times 1$卷积，节省33%的计算量。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216212839575.png" alt="非对称卷积核分解"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216212906143.png" alt="n*n卷积核非对称分解"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216213045585.png" alt="Inception v2中的Inception module"></p>
</li>
</ul>
<h3 id="高效降维"><a href="#高效降维" class="headerlink" title="高效降维"></a>高效降维</h3><p>Inception v2中通过低维嵌入完成空间聚合从而实现高效的降维。</p>
<p>传统的方法包括以下两种：</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216213338005.png" alt="传统降维方法"></p>
<ul>
<li>先将特征图(通道)数目扩大（一般使用$1 \times 1$卷积），然后再使用池化层来减少特征图(通道)数目，但是$1 \times 1$卷积会有非常大的计算开销。</li>
<li>先做池化减少特征图(通道)数目，然后再使用$1 \times 1$卷积对其特征图(通道)数目放大，不过显然首先使用池化会造成信息硬性丢失，在此之后再使用$1 \times 1$卷积去增加特征图(通道)数目就没有太大意义了。</li>
</ul>
<p>但是，在Inception v2中，作者在降低计算量(即减小特征图大小)的同时，避免表征瓶颈。采用两个并行的、步长为2的模块。其中一个是池化层(最大池化或均值池化)，另一个是步长为2的两个卷积层。这两个模块的输出堆叠在一起构成真正的输出，这样就增大了最终输出的特征图数目。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216213407044.png" alt="Inception v2中的高效降维方法"></p>
<p>Inception v2的整体结构如下图：</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216213944269.png" alt="Inception v2的结构"></p>
<h3 id="辅助分类器的效果"><a href="#辅助分类器的效果" class="headerlink" title="辅助分类器的效果"></a>辅助分类器的效果</h3><p>在训练时并没有促进收敛。当训练快结束时，拥有辅助分类器的网络的准确率会比没有辅助分类器的网络的准确率高。<br>GoogleNet在网络的两个不同的地方设置了辅助分类器。将浅层的那个辅助分类器移走对于网络最后的结果没有任何负面作用，即是无用的。结合前面提到的，GoogleNet提出的辅助分类器能够帮助低层特征训练的假设是错误的。实际上，辅助分类器就是一个正则化方法。如果辅助分类器采用BN或者引入dropout，网络的主分类器能够取得更好的结果，证明了辅助分类器就是一个正则化方法。同时也为BN是一个正则化方法的猜想提供了一点支持。</p>
<h3 id="Label-Smoothing"><a href="#Label-Smoothing" class="headerlink" title="Label Smoothing"></a><a href="https://www.zhihu.com/question/65339831/answer/236892343" target="_blank" rel="noopener">Label Smoothing</a></h3><p>Inception v2中改进了目标函数。原来的目标函数，在单类情况下，如果某一类概率接近1，其他的概率接近0，那么会导致交叉熵取log后变得很大很大。从而导致两个问题：过拟合；导致样本属于某个类别的概率非常的大，模型太过于自信自己的判断。所以，使用了一种平滑方法，可以使得类别概率之间的差别没有那么大。这项改动就是label smooth，提升了0.2%个点。当然这种做法也将背景类暗含进了分类类别中（1000-&gt;1001）。</p>
<p>综上，可以总结出Inception v2的四条<a href="https://zhuanlan.zhihu.com/p/32702113" target="_blank" rel="noopener">设计原则</a>：</p>
<ul>
<li>慎用瓶颈层(Inception v1的瓶颈层)来表征特征，尤其是在模型底层。前馈神经网络是一个从输入层到分类器的无环图，这就明确了信息流动的方向。对于网络中任何将输入和输出分开的隔断，都可以评估出通过该隔断的信息量。在网络中，应该避免压缩率较高的瓶颈层。通常，表征尺寸应该从输入到输出逐渐减小，直到表征用来完成当前的任务(识别、分类等)。理论上，信息内容不能只用表征维度评估，因为表征维度作为一个粗略的估计，忽略了相关结构等重要因素。</li>
<li>更高维度的表征更容易在网络的局部中处理。增加卷积神经网络中每层的卷积核个数能够获得耦合性更低的特征。这样，获得的各个特征具有高内聚低耦合的特点，能够加速收敛。两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种‘组合’，其中一个神经元的兴奋会促进另一个的兴奋。CNN中位于顶层的各个卷积核就是为了获取这种‘组合’特征，即高内聚低耦合特征。</li>
<li>通过低维度嵌入来完成空间聚合，如采用瓶颈层进行特征维度缩减，这样几乎不影响表征能力，但通常限于网络模型顶层部分。例如，在使用$3 \times 3$卷积进行空间聚合时，可以使用瓶颈层降低输入表征的维度，并且几乎没有出现预期的不良后果。作者猜测，网络顶层输出的特征层尺寸较小、信息量丰富，导致各个特征层之间关联性较高，因此降维导致的信息损失很小。鉴于这些信号应易于压缩，降维甚至可以促进更快的学习。</li>
<li>平衡网络的宽度和深度。优化网络性能可以认为是平衡每个阶段(层)的卷积核数目和网络深度。在合理分配计算/内存资源的前提下，同时增加宽度和深度能够提升网络性能。</li>
</ul>
<p>Inception-v2的结构中如果辅助分类器添加了BN，就成了Inception-v3。</p>
<h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception v4"></a>Inception v4</h2><p>paper地址: <a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></p>
<p>Inception v4中将Inception module与ResNet的残差结构相结合，通过残差连接加速Inception网络的训练。提出了两个Inception残差网络，包括Inception-ResNet-v1、Inception-ResNet-v2；一个Inception网络Inception-v4，证明了在算法开销相近时，残差Inception网络比没有残差连接的Inception网络的性能稍稍好一些。</p>
<h3 id="纯Inception-module"><a href="#纯Inception-module" class="headerlink" title="纯Inception module"></a>纯Inception module</h3><p>旧的Inception modules以分布式的方式训练，每个副本被分割为多个子网以适应内存空间。然而，Inception结构具有很高的可调性，意味着多个层中卷积核的数目可以任意改变，但并不会影响网络整体性能。为了优化训练速度，作者认真地调节了层的尺寸，通过调节层的尺寸来平衡各个模型子网间的计算量。对比之下，通过引入TensorFlow可以使目前多数模型不必采用分布式训练。这种进展一定程度上归功于反向传播算法的内存优化，即认真地鉴别哪些张量是计算梯度所必须的、采用结构化计算，以此减少张量数量。在此之前，作者对于改变结构选择一直很保守，实验仅限于改变网络模型某个部分，其余部分不变。由于没有简化早期的网络结构选择，导致了网络比实际需要的网络复杂。在作者构建Inception-V4的实验中，抛下了关于改变结构选择的不必要的包袱，为每个网格大小的Inception模块做出统一的选择。</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220206037.png" alt="Inception v4网络"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220323299.png" alt="纯Inception-v4和Inception-ResNet-v2网络主干(stem)的结构，是图1和图8的输入部分"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220415509.png" alt="纯Inception-v4网络中35*35网格modules的结构，是图1中的Inception-A模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220435327.png" alt="纯Inception-v4网络中17*17网格modules的结构，是图1中的Inception-B模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220449592.png" alt="纯Inception-v4网络中8*8网格modules的结构，是图1中的Inception-C模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220512134.png" alt="35*35至17*17残差module的结构，Reduction-A。该模块的不同变种(过滤器数目不同)应用于图1和图8中的每一个在本文中提出的新Inception(-v4，-ResNet-v1，-ResNet-v2)"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216220539079.png" alt="17*17至8*8 grid-reduction module的结构，Reduction-B。图1中纯Inception-4v网络使用的残差结构"></p>
<h3 id="残差Inception模块"><a href="#残差Inception模块" class="headerlink" title="残差Inception模块"></a>残差Inception模块</h3><p><img src="/2019/12/16/Inception-Network/image-20191216221259037.png" alt="Inception-ResNet-v1和Inception-ResNet-v2"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221127684.png" alt="Inception-ResNet-v1的主干"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221429471.png" alt="Inception-ResNet-v1中Inception-ResNet-C模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221528638.png" alt="Inception-ResNet-v2中Inception-ResNet-A模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221644132.png" alt="Inception-ResNet-v2中Inception-ResNet-B模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221721005.png" alt="Inception-ResNet-v1中Reduction-B模块"></p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221756259.png" alt="Inception-ResNet-v2中Reduction-C模块"></p>
<p>在残差Inception网络中，使用了比原始Inception模块计算开销更低的Inception模块。每个Inception模块后面都添加一个过滤器扩展层(没有激活函数的$1 \times1$卷积层)，在与输入相加之前，用来增加过滤器组的维度(深度)，使其与输入的深度一致。这么做是为了补偿Inception模块产生的降维。</p>
<p>作者尝试了多种残差Inception，文中仅详细介绍两种：Inception-ResNet-v1，计算量与Inception-v3相似；另一种是Inception-ResNet-v2，计算量与新提出的Inception-v4的主体计算量相似。实际中，Inception-v4的单步时间比较慢，可能是拥有大量的层导致。</p>
<p>残差Inception与非残差Inception的另一个技术差异：Inception-ResNet中，仅在传统层上使用BN，并未在完成输入与输出相加的层使用BN。在所有层都使用BN是合理的、有益的，但是为了使每个模型副本能够在单个GPU上训练，并未这么做。事实证明，拥有较大核(激活尺寸/卷积核)的层消耗的内存，与整个GPU内存相比是不成比例的，明显较高。通过去掉这些层的BN操作，能够大幅提高Inception模块的数目。作者希望能够有更好的计算资源利用方法，从而省去Inception模块数目和层数之间的权衡。</p>
<h3 id="残差模块缩放"><a href="#残差模块缩放" class="headerlink" title="残差模块缩放"></a>残差模块缩放</h3><p>作者发现，如果过滤器数目超过1000，残差网络将变得不稳定，并且网络在训练的早期就‘死亡’了，即迭代上万次之后，在平均池化层之前的层只输出0。即使降低学习率、添加额外的BN层也无法避免。</p>
<p>作者发现，在将残差与其上一层的激活值相加之前，将残差缩放，这样可以使训练过程稳定。通常采用0.1至0.3之间的缩放因子来缩放残差层，然后再将其添加到累加层的激活层。如下图：</p>
<p><img src="/2019/12/16/Inception-Network/image-20191216221838461.png" alt="残差缩放模块"></p>
<p>Inception-ResNet modules的通用缩放机制：该机制要适用于常见的ResNet，即使用任意子网代替Inception模块的ResNet。缩放模块仅作用于最后的线性激活值，缩放因子为常数，通常为0.1。</p>
<p>其他深度网络也出现了类似问题。在一个非常深的残差网络中，研究者提出了两阶段训练。第一阶段，称为预热阶段，以较低的学习率训练，然后在第二阶段采用较高的学习率。本文作者发现，如果过滤器数目非常高，即使学习率极低(如0.00001)也无法解决不稳定现象，并且第二阶段较高的学习率很可能降低第一阶段的学习效果，降低模型性能。作者认为使用缩放更为可靠。</p>
<p>尽管缩放在某些地方不是必须的，但是并未发现缩放会降低最终的准确性，而且缩放在一定程度上会使训练变得稳定。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://zhuanlan.zhihu.com/p/32702113" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32702113</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/52802896" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/52802896</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/32702209" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32702209</a></p>
<p><a href="https://www.zhihu.com/question/66396783" target="_blank" rel="noopener">https://www.zhihu.com/question/66396783</a></p>
<p><a href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202" target="_blank" rel="noopener">https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>VGG</title>
    <url>/2019/12/14/VGG/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><p>VGG由牛津大学的Karen Simonyan和Andrew Zisserman提出，在2014年的ILSVRC中top-5 error rate达到了7.3%。VGG可以说是CNN中最重要的模型之一，它强调了深度在CNN模型中的重要作用(我之前的一篇[博客][<a href="https://quan-sun.github.io/2019/11/24/为什么神经网络越深越好/#more]介绍了深度对于神经网络的影响)。">https://quan-sun.github.io/2019/11/24/为什么神经网络越深越好/#more]介绍了深度对于神经网络的影响)。</a></p><p>VGG研究卷积网络深度的初衷是想搞清楚卷积网络深度是如何影响大规模图像分类与识别的精度和准确率的。VGG在加深网络层数同时为了避免参数过多，所有层都采用$3\times3$的小卷积核，stride设置为1。VGG的输入图像大小为$224 \times 244$，在训练集上对所有图像计算RGB均值，然后将处理后的图像作为传入VGG卷积网络，使用$3\times3$或者$1\times1$的filter，stride设置为1。</p><a id="more"></a>


<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="https://www.cs.toronto.edu/~frossard/post/vgg16/vgg16.png" alt="VGG19 architecture"></p>
<p><img src="/2019/12/14/VGG/image-20191214170328471.png" alt="ConvNet configurations"></p>
<p>VGG根据权重层的数量的不同分为VGG11/VGG13/VGG16/VGG19。可以看到VGG由不同数量的卷积层和3层全连接层组成，并且不是每个卷积层后面都接有pooling层。</p>
<p>参数的数量如下：</p>
<p><img src="/2019/12/14/VGG/image-20191214171403932.png" alt="number of parameters"></p>
<h2 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h2><h4 id="使用-3-times3-的kernel代替较大的kernel"><a href="#使用-3-times3-的kernel代替较大的kernel" class="headerlink" title="使用$3\times3$的kernel代替较大的kernel"></a>使用$3\times3$的kernel代替较大的kernel</h4><p>对于给定的感受野，采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且参数更少。具体来说，使用两个$3\times3$的kernel代替$5\times5$的kernel，三个$3\times3$的kernel代替$7\times7$的kernel。这么做可以在保证具有相同感受野的条件下，提升网络的深度，在一定程度上提升神经网络的效果。</p>
<p>3个stride为1的$3\times3$卷积核的叠加作用可看成一个大小为7的感受野（即3个$3\times3$连续卷积相当于1个$7\times7$卷积），其参数总量为 $3\times(9\times C^2)$ ，但是，直接使用7x7卷积核，其参数总量为 $49 \times C^2$ ，这里 C 是指输入和输出的通道数。$3\times(9\times C^2)$小于$49 \times C^2$，所以3个stride为1的$3\times3$卷积核减少了参数，同时$3\times3$卷积核有利于更好地保持图像性质。</p>
<p><img src="https://miro.medium.com/max/689/1*NMC4KrYIciGdE_FaazxF7w.png" alt="2 layers of 3×3 filters already covered the 5×5 area"></p>
<p>source: <a href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" target="_blank" rel="noopener">https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11</a></p>
<h4 id="局限"><a href="#局限" class="headerlink" title="局限"></a>局限</h4><ul>
<li>VGG会耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用。其中绝大多数的参数都是来自于第一个全连接层，而且VGG有3个全连接层。</li>
<li>在此之前，CNN很少有突破10层的，而VGG在加深CNN的深度方面做出了重要的贡献。但是VGG不能无限制的加深网络，当网络加深到一定层数之后就会出现训练效果褪化、梯度消失等问题。这些问题正是为什么很长一段时间神经网络没办法做到很深的原因。之后会说到BN和ResNet会分别解决这两种问题。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexNet</title>
    <url>/2019/12/14/AlexNet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></p><p>AlexNet是2012年ILSVRC的冠军模型，top-5 error rate达到15.3%，甩了第二名10.8%，完全碾压其他传统的依赖hand-craft特征的计算机视觉方法。它的出现绝对是深度学习的里程碑，这是第一次在大规模的数据集上实现了深层卷积网络的结构，从此开始了深度学习的热潮。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="/2019/12/14/AlexNet/image-20191214153724495.png" alt="image-20191214153724495"></p><p>AlexNet总共有8哥权重层，其中包括5个卷积层和3个全连接层。</p><p><img src="/2019/12/14/AlexNet/alexnet.png" alt="architecture"></p><p>第1、2卷积层后连有LRN(Local Response Normalization)层，每个LRN及最后层卷积层后跟有最大池化层，并且每个权重层均有RELU激活函数。全连接后使用dropout解决过拟合。</p><a id="more"></a>





<table>
<thead>
<tr>
<th align="center">layer</th>
<th align="center">Stride</th>
<th align="center">Kernel size</th>
<th align="center">feature map</th>
<th align="center">PADDING</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Conv1</td>
<td align="center">4</td>
<td align="center">$11\times11\times96$</td>
<td align="center">$55\times55\times96$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">Pooling1</td>
<td align="center">2</td>
<td align="center">$3\times3$</td>
<td align="center">$27\times27\times96$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">Conv2</td>
<td align="center">1</td>
<td align="center">$5\times5\times256$</td>
<td align="center">$27\times27\times256$</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">Pooling2</td>
<td align="center">2</td>
<td align="center">$3\times3$</td>
<td align="center">$13\times13\times256$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">Conv3</td>
<td align="center">1</td>
<td align="center">$3\times3\times384$</td>
<td align="center">$13\times13\times384$</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">Conv4</td>
<td align="center">1</td>
<td align="center">$3\times3\times384$</td>
<td align="center">$13\times13\times384$</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">Conv5</td>
<td align="center">1</td>
<td align="center">$3\times3\times256$</td>
<td align="center">$13\times13\times256$</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">Pooling5</td>
<td align="center">2</td>
<td align="center">$3\times3$</td>
<td align="center">$6\times6\times256$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">FC6</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">4096</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">FC7</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">4096</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">FC8</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">1000</td>
<td align="center"></td>
</tr>
</tbody></table>
<h2 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h2><p>1.Training on Multiple GPUs</p>
<p>2.ReLU Nonlinearity</p>
<p>传统神经网络激活函数通常为反正切或是sigmoid，AlexNet使用RELU作为激活函数，相比于反正切，该方法训练速度大约有6倍提升。</p>
<p>3.Local Response Normalization</p>
<p><img src="/2019/12/14/AlexNet/image-20191214160951499.png" alt="LRN"></p>
<p>LRN加在RELU的激活后面，能够增加网络的泛化能力，并在ILSVRC-2012上降低1%的错误率。不过后来的网络证明了LRN并非CNN中必须包含的层，甚至有些网络加入LRN后模型表现反而降低了。</p>
<p>4.Overlapping Pooling</p>
<p>重叠池化是指池化步伐小于kernel size，池化后的feature map的感受野其实是有部分重叠的,文章指出这样做可以防止过拟合。但是，后面的网络鲜有继续使用的，因为有更好的防止过拟合的技术出现，比如BN已经可以解决过拟合的问题。</p>
<p>5.Data Augmentation</p>
<p>使用Random Crop和flip进行数据增强，从而扩充训练样本的数量。具体做法就是将图片resize到$256\times256$，然后从中随机crop出$224\times224$大小的patch训练；测试时从四个角和中心分别crop，然后水平翻转图像，这就得到了10张测试图片，然后对于这10张测试图片得到的结果取平均值。另一种数据增强方法是转换RGB通道的强度，大约降低了1% error rate，但是这个方法之后的模型很少使用了。</p>
<p>6.Dropout</p>
<p>Dropout通过训练时随机丢弃部分神经元从而减少过拟合的风险。这么做也可以迫使这些神经元去学习互补的一些特征。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>Tips to make GANs work</title>
    <url>/2019/12/14/Tips-to-make-GANs-work/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>A great <a href="https://github.com/soumith/ganhacks" target="_blank" rel="noopener">git repo</a> with 7.6k stars about training GANs.</p><p>While research in Generative Adversarial Networks (GANs) continues to improve the fundamental stability of these models, we use a bunch of tricks to train them and make them stable day to day.</p><h3 id="Normalize-the-inputs"><a href="#Normalize-the-inputs" class="headerlink" title="Normalize the inputs"></a>Normalize the inputs</h3><ul>
<li>normalize the images between -1 and 1</li>
<li>Tanh as the last layer of the generator output</li>
</ul><a id="more"></a>


<h3 id="A-modified-loss-function"><a href="#A-modified-loss-function" class="headerlink" title="A modified loss function"></a>A modified loss function</h3><p>In GAN papers, the loss function to optimize G is <code>min (log 1-D)</code>, but in practice folks practically use <code>max log D</code></p>
<ul>
<li>because the first formulation has vanishing gradients early on Goodfellow et. al (2014)</li>
</ul>
<p>In practice, works well:</p>
<ul>
<li>Flip labels when training generator: real = fake, fake = real</li>
</ul>
<p>Use a spherical Z</p>
<ul>
<li>Don’t sample from a Uniform distribution</li>
</ul>
<p><img src="/2019/12/14/Tips-to-make-GANs-work/cube.png" alt="cube" title="Cube"></p>
<ul>
<li>Sample from a gaussian distribution</li>
</ul>
<p><img src="/2019/12/14/Tips-to-make-GANs-work/sphere.png" alt="sphere" title="Sphere"></p>
<ul>
<li>When doing interpolations, do the interpolation via a great circle, rather than a straight line from point A to point B</li>
<li>Tom White’s <a href="https://arxiv.org/abs/1609.04468" target="_blank" rel="noopener">Sampling Generative Networks</a> ref code <a href="https://github.com/dribnet/plat" target="_blank" rel="noopener">https://github.com/dribnet/plat</a> has more details</li>
</ul>
<h3 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h3><ul>
<li>Construct different mini-batches for real and fake, i.e. each mini-batch needs to contain only all real images or all generated images.</li>
<li>when batchnorm is not an option use instance normalization (for each sample, subtract mean and divide by standard deviation).</li>
</ul>
<p><img src="/2019/12/14/Tips-to-make-GANs-work/batchmix.png" alt="batchmix" title="BatchMix"></p>
<h3 id="Avoid-Sparse-Gradients-ReLU-MaxPool"><a href="#Avoid-Sparse-Gradients-ReLU-MaxPool" class="headerlink" title="Avoid Sparse Gradients: ReLU, MaxPool"></a>Avoid Sparse Gradients: ReLU, MaxPool</h3><ul>
<li>the stability of the GAN game suffers if you have sparse gradients</li>
<li>LeakyReLU = good (in both G and D)</li>
<li>For Downsampling, use: Average Pooling, Conv2d + stride</li>
<li>For Up sampling, use: Pixel Shuffle, ConvTranspose2d + stride<ul>
<li>Pixel Shuffle: <a href="https://arxiv.org/abs/1609.05158" target="_blank" rel="noopener">https://arxiv.org/abs/1609.05158</a></li>
</ul>
</li>
</ul>
<h3 id="Use-Soft-and-Noisy-Labels"><a href="#Use-Soft-and-Noisy-Labels" class="headerlink" title="Use Soft and Noisy Labels"></a>Use Soft and Noisy Labels</h3><ul>
<li>Label Smoothing, i.e. if you have two target labels: Real=1 and Fake=0, then for each incoming sample, if it is real, then replace the label with a random number between 0.7 and 1.2, and if it is a fake sample, replace it with 0.0 and 0.3 (for example).<ul>
<li>Salimans et. al. 2016</li>
</ul>
</li>
<li>make the labels the noisy for the discriminator: occasionally flip the labels when training the discriminator</li>
</ul>
<h3 id="DCGAN-Hybrid-Models"><a href="#DCGAN-Hybrid-Models" class="headerlink" title="DCGAN / Hybrid Models"></a>DCGAN / Hybrid Models</h3><ul>
<li>Use DCGAN when you can. It works!</li>
<li>if you cant use DCGANs and no model is stable, use a hybrid model :  KL + GAN or VAE + GAN</li>
</ul>
<h3 id="Use-stability-tricks-from-RL"><a href="#Use-stability-tricks-from-RL" class="headerlink" title="Use stability tricks from RL"></a>Use stability tricks from RL</h3><ul>
<li>Experience Replay<ul>
<li>Keep a replay buffer of past generations and occasionally show them</li>
<li>Keep checkpoints from the past of G and D and occasionally swap them out for a few iterations</li>
</ul>
</li>
<li>All stability tricks that work for deep deterministic policy gradients</li>
<li>See Pfau &amp; Vinyals (2016)</li>
</ul>
<h3 id="Use-the-ADAM-Optimizer"><a href="#Use-the-ADAM-Optimizer" class="headerlink" title="Use the ADAM Optimizer"></a>Use the ADAM Optimizer</h3><ul>
<li>optim.Adam rules!<ul>
<li>See Radford et. al. 2015</li>
</ul>
</li>
<li>Use SGD for discriminator and ADAM for generator</li>
</ul>
<h3 id="Track-failures-early"><a href="#Track-failures-early" class="headerlink" title="Track failures early"></a>Track failures early</h3><ul>
<li>D loss goes to 0: failure mode</li>
<li>check norms of gradients: if they are over 100 things are screwing up</li>
<li>when things are working, D loss has low variance and goes down over time vs having huge variance and spiking</li>
<li>if loss of generator steadily decreases, then it’s fooling D with garbage (says martin)</li>
</ul>
<h3 id="Don’t-balance-loss-via-statistics-unless-you-have-a-good-reason-to"><a href="#Don’t-balance-loss-via-statistics-unless-you-have-a-good-reason-to" class="headerlink" title="Don’t balance loss via statistics (unless you have a good reason to)"></a>Don’t balance loss via statistics (unless you have a good reason to)</h3><ul>
<li>Don’t try to find a (number of G / number of D) schedule to uncollapse training</li>
<li>It’s hard and we’ve all tried it.</li>
<li>If you do try it, have a principled approach to it, rather than intuition</li>
</ul>
<p>For example</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> lossD &gt; <span class="string">A:</span></span><br><span class="line">  train D</span><br><span class="line"><span class="keyword">while</span> lossG &gt; <span class="string">B:</span></span><br><span class="line">  train G</span><br></pre></td></tr></table></figure>

<h3 id="If-you-have-labels-use-them"><a href="#If-you-have-labels-use-them" class="headerlink" title="If you have labels, use them"></a>If you have labels, use them</h3><ul>
<li>if you have labels available, training the discriminator to also classify the samples: auxiliary GANs</li>
</ul>
<h3 id="Add-noise-to-inputs-decay-over-time"><a href="#Add-noise-to-inputs-decay-over-time" class="headerlink" title="Add noise to inputs, decay over time"></a>Add noise to inputs, decay over time</h3><ul>
<li>Add some artificial noise to inputs to D (Arjovsky et. al., Huszar, 2016)<ul>
<li><a href="http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/" target="_blank" rel="noopener">http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/</a></li>
<li><a href="https://openreview.net/forum?id=Hk4_qw5xe" target="_blank" rel="noopener">https://openreview.net/forum?id=Hk4_qw5xe</a></li>
</ul>
</li>
<li>adding gaussian noise to every layer of generator (Zhao et. al. EBGAN)<ul>
<li>Improved GANs: OpenAI code also has it (commented out)</li>
</ul>
</li>
</ul>
<h3 id="not-sure-Train-discriminator-more-sometimes"><a href="#not-sure-Train-discriminator-more-sometimes" class="headerlink" title="[not-sure] Train discriminator more (sometimes)"></a>[not-sure] Train discriminator more (sometimes)</h3><ul>
<li>especially when you have noise</li>
<li>hard to find a schedule of number of D iterations vs G iterations</li>
</ul>
<h3 id="not-sure-Batch-Discrimination"><a href="#not-sure-Batch-Discrimination" class="headerlink" title="[not-sure] Batch Discrimination"></a>[not-sure] Batch Discrimination</h3><ul>
<li>Mixed results</li>
</ul>
<h3 id="Discrete-variables-in-Conditional-GANs"><a href="#Discrete-variables-in-Conditional-GANs" class="headerlink" title="Discrete variables in Conditional GANs"></a>Discrete variables in Conditional GANs</h3><ul>
<li>Use an Embedding layer</li>
<li>Add as additional channels to images</li>
<li>Keep embedding dimensionality low and upsample to match image channel size</li>
</ul>
<h3 id="Use-Dropouts-in-G-in-both-train-and-test-phase"><a href="#Use-Dropouts-in-G-in-both-train-and-test-phase" class="headerlink" title="Use Dropouts in G in both train and test phase"></a>Use Dropouts in G in both train and test phase</h3><ul>
<li>Provide noise in the form of dropout (50%).</li>
<li>Apply on several layers of our generator at both training and test time</li>
<li><a href="https://arxiv.org/pdf/1611.07004v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.07004v1.pdf</a></li>
</ul>
<h3 id="not-sure-Batch-Discrimination-1"><a href="#not-sure-Batch-Discrimination-1" class="headerlink" title="[not-sure] Batch Discrimination"></a>[not-sure] Batch Discrimination</h3><ul>
<li>Train D and G standalone without updating weights of the other and make sure the losses go down.</li>
</ul>
<h3 id="Authors"><a href="#Authors" class="headerlink" title="Authors"></a>Authors</h3><ul>
<li>Soumith Chintala</li>
<li>Emily Denton</li>
<li>Martin Arjovsky</li>
<li>Michael Mathieu</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Study Notes of Machine Learning V1</title>
    <url>/2019/12/11/Study-Notes-of-Machine-Learning-V1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="Basic-concepts"><a href="#Basic-concepts" class="headerlink" title="Basic concepts"></a>Basic concepts</h3><h4 id="Bias-and-Variance"><a href="#Bias-and-Variance" class="headerlink" title="Bias and Variance"></a>Bias and Variance</h4><p><code>bias</code> is the difference between ground truth and expectation of prediction of your model, which measures fitting ability of models; <code>variance</code> is the difference between expectation of prediction of your model and prediction, that is difference between results of different datasets feeding in your model, which measures stability of models.</p><a id="more"></a>
<p>In supervised learning, model’s generalized error consists of bias, variance and noise, which can be formulated by $Err(x)={Bias}^2+Variance+IrreducibleError$.</p>
<p><code>bias</code> and <code>variance</code> are standing in two sides of a balance, so reduction of one will increase the other. Obviously, what we do in machine learning is bias-variance trade-off. Taking neural networks as an example, NNs have strong fitting ability, which means they have low bias and high variance, so we need to reduce variance with increasing bias.  </p>
<h4 id="Overfitting-and-Underfitting"><a href="#Overfitting-and-Underfitting" class="headerlink" title="Overfitting and Underfitting"></a>Overfitting and Underfitting</h4><p><code>overfitting</code> and <code>underfitting</code> are associated with <code>bias</code> and <code>variance</code>. Low bias and high variance lead to overfitting, which means your model is too complex for real data and of low generalization; Low variance and high bias lead to underfitting, which means your model is too simple to fit real data.</p>
<p>For a specific task, with increasing of model capacity (it represents complexity of models, which can be understood of number of parameters) the bias will reduce and variance will increase. Obviously, there is an optimal capacity leading best bias-variance trade-off.</p>
<p>Solutions for underfitting:</p>
<ul>
<li>More features</li>
<li>More complex model</li>
</ul>
<p>Solutions for overfitting:</p>
<ul>
<li><p>Data augmentation</p>
</li>
<li><p>Early stopping</p>
</li>
<li><p>Regularization</p>
</li>
<li><p>Dropout </p>
</li>
<li><p>Ensemble </p>
</li>
<li><p><del>Batch Normalization</del>(BN can’t prevent overfitting according to <a href="https://arxiv.org/pdf/1611.03530.pdf" target="_blank" rel="noopener">paper</a>, it just can stablize training process)</p>
<blockquote>
<p>如果硬要说是防止过拟合，可以这样理解：BN每次的mini-batch的数据都不一样，但是每次的mini-batch的数据都会对moving mean和moving variance产生作用，可以认为是引入了噪声，这就可以认为是进行了data augmentation，而data augmentation被认为是防止过拟合的一种方法。因此，可以认为用BN可以防止过拟合。</p>
</blockquote>
</li>
</ul>
<h4 id="Gradient-Descent-and-Backpropagation"><a href="#Gradient-Descent-and-Backpropagation" class="headerlink" title="Gradient Descent and Backpropagation"></a>Gradient Descent and Backpropagation</h4><h5 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h5><p><a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="noopener">Gradient descent</a> is a very important idea in deep learning and machine learning, which boosts the development of AI. Of course, some researches without gradient descent were proposed, such as Newton Method, however, GD is still mainstream algorithm in training models. </p>
<blockquote>
<p><strong>Gradient descent</strong> is a <a href="https://en.wikipedia.org/wiki/Category:First_order_methods" target="_blank" rel="noopener">first-order</a> <a href="https://en.wikipedia.org/wiki/Iterative_algorithm" target="_blank" rel="noopener">iterative</a> <a href="https://en.wikipedia.org/wiki/Mathematical_optimization" target="_blank" rel="noopener">optimization</a> <a href="https://en.wikipedia.org/wiki/Algorithm" target="_blank" rel="noopener">algorithm</a> for finding the minimum of a function. To find a <a href="https://en.wikipedia.org/wiki/Local_minimum" target="_blank" rel="noopener">local minimum</a> of a function using gradient descent, one takes steps proportional to the <em>negative</em> of the <a href="https://en.wikipedia.org/wiki/Gradient" target="_blank" rel="noopener">gradient</a> (or approximate gradient) of the function at the current point. </p>
</blockquote>
<p>What GD do is updating parameters of model with gradient so that make loss descent.</p>
<p><img src="https://hackernoon.com/hn-images/0*rBQI7uBhBKE8KT-X.png" alt="Gradient Descent"> </p>
<p><img src="https://hackernoon.com/hn-images/0*8yzvd7QZLn5T1XWg.jpg" alt></p>
<h5 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h5><p><a href="https://skymind.ai/wiki/backpropagation" target="_blank" rel="noopener">Backpropagation</a> is an application of chain rule.</p>
<blockquote>
<p>A neural network propagates the signal of the input data forward through its parameters towards the moment of decision, and then <em>backpropagates</em> information about the error, in reverse through the network, so that it can alter the parameters. This happens step by step:</p>
<ul>
<li>The network makes a guess about data, using its parameters</li>
<li>The network’s is measured with a loss function</li>
<li>The error is backpropagated to adjust the wrong-headed parameters</li>
</ul>
</blockquote>
<p>See this <a href="https://brilliant.org/wiki/backpropagation/" target="_blank" rel="noopener">post1</a> and <a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="noopener">post2</a> for more details.</p>
<p><img src="https://pic2.zhimg.com/v2-8e30a45198d332dae959c57e04fdc267_r.jpg" alt="backpropagation"></p>
<p><img src="https://pic3.zhimg.com/v2-c96e284f4ab319a02fdd762367b58774_r.jpg" alt></p>
<h4 id="Gradient-vanishing-and-Gradient-exploding"><a href="#Gradient-vanishing-and-Gradient-exploding" class="headerlink" title="Gradient vanishing and Gradient exploding"></a>Gradient vanishing and Gradient exploding</h4><h5 id="Gradient-Vanishing"><a href="#Gradient-Vanishing" class="headerlink" title="Gradient Vanishing"></a>Gradient Vanishing</h5><p>As more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train. Certain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.</p>
<p><img src="https://miro.medium.com/max/4384/1*6A3A_rt4YmumHusvTvVTxw.png" alt="sigmoid and its gradients"></p>
<p>What’s worse, we have known that neural networks’ training is based on back propagation and BP is based on chain rule, so if these values in BP are all small, such as 0.01, gradient of the first layer may be ${0.01}^n$ which is approaching to 0. According to Gradient Descent, the NNs won’t be effectively trained due to 0 gradient.</p>
<p>Solutions: </p>
<ul>
<li><p>Other activation function, such as ReLU </p>
<p>Rectifiers such as <strong>ReLU</strong> suffer less from Vanishing Gradient problem, because they only saturate in one direction, which maps $x$ into $max(0,x)$.</p>
<p>However, there still dead ReLU problem, because negative value will be mapped to zero so that some neurons won’t be activated. We can use small learning rate to partially solve this problem. Leaky ReLU and ELU are also solutions.</p>
</li>
<li><p>LSTM </p>
<p>Long Short Term Memory Networks are generally used to tackle Vanishing Gradient problem when you are working on RNN. LTSMs help to solve long term dependencies and can memorize previous data easily.</p>
</li>
<li><p><del>Residual networks</del>(according to paper of ResNet, it ‘s not for solving gradient vanishing)</p>
<p><img src="https://miro.medium.com/max/770/1*mxJ5gBvZnYPVo0ISZE5XkA.png" alt="skip connection"></p>
</li>
<li><p>Batch Normalization</p>
<p><img src="https://miro.medium.com/max/1634/1*XCtAytGsbhRQnu-x7Ynr0Q.png" alt></p>
<p>The nature of <code>Batch Normalization</code> is stablizing networks.</p>
<p>Batch Normalization can normalize all data into same distribution (zero mean, one standard deviation Gaussian). From above image we can see that when $|x|$ is too large the gradient of output of sigmoid is approaching to zero. BN normalizes the input $|x|$ so that most of it can fall into center area (green region), which means it pull data from saturated region to non-saturated region.</p>
<p>Let see BN from another perspective. For example, there is $f_2=f_1(w^T*x+b)$ in forward propagation, so  we can get $\frac{\partial f_2}{\partial x}=\frac{\partial f_2}{\partial f_1}w$ in back propagation and the value of w can lead to gradient vanishing problem. BN normalizes output of each layer into same mean and variance, which removes the effect of w’s enlarging and reducing.</p>
</li>
</ul>
<h5 id="Gradient-Exploding"><a href="#Gradient-Exploding" class="headerlink" title="Gradient Exploding"></a>Gradient Exploding</h5><blockquote>
<p>Exploding gradients are a problem when large error gradients accumulate and result in very large updates to neural network model weights during training. Gradients are used during training to update the network weights, but when the typically this process works best when these updates are small and controlled. When the magnitudes of the gradients accumulate,  an unstable network is likely to occur, which can cause poor prediction results or even a model that reports nothing useful what so ever. </p>
<p>Exploding gradients can cause problems in the training of artificial neural networks. When there are exploding gradients, an unstable network can result and the learning cannot be completed. The values of the weights can also become so large as to overflow and result in something called NaN values. NaN values, which stands for not a number, are values that represent an undefined or unrepresentable values. It is useful to know how to identify exploding gradients in order to correct the training.  - <a href="https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem" target="_blank" rel="noopener">Deep AI</a></p>
</blockquote>
<p>Solutions:</p>
<ul>
<li><p>Gradient clipping</p>
<p>Gradient clipping places a predefined threshold on the gradients to prevent it from getting too large, and by doing this it doesn’t change the direction of the gradients it only change its length.</p>
</li>
<li><p>LSTM</p>
</li>
<li><p>Batch Normalization</p>
</li>
<li><p>Regularization</p>
<p>i.e. L2 regularization. $Loss=(y-W^Tx)^2+\alpha ||W||^2$. When exploding happens, norm of weights will be very large, but it can be partially limited by regularization term. What’s more, we know that regularization can make weights small. </p>
</li>
</ul>
<h4 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h4><p>The aim of using activation function is adding non-linearity into our models, which can boost their representation ability and solve problems that linear models fail to.</p>
<p><strong>Sigmoid</strong></p>
<p><img src="https://pic4.zhimg.com/80/v2-45975854a0d00d84e575851b278a88a9_hd.jpg" alt="sigmoid"></p>
<p><img src="https://pic4.zhimg.com/50/v2-c14e1eb9092aa343fdc89d5e244fac19_hd.jpg" alt="sigmoid and its gradients"></p>
<p><strong>tanh</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-3528e66d0e12b35f778fe0ed21d2ced2_hd.jpg" alt="tanh and its gradients"></p>
<p><strong>ReLU</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-f6fb4bd3e9e4b343f87138b930792108_hd.jpg" alt="RELU"></p>
<p><img src="https://pic4.zhimg.com/50/v2-96c46de23a1f236918844dd490870c49_hd.jpg" alt="RELU and its gradients"></p>
<p>ReLU and its variants are based on $g(x;\alpha)=max(0,z)+\alpha * min(0,z)$. </p>
<p>$\alpha = 0$, it is ReLU whose gradient is computed very fast because it is either 0 or 1;</p>
<p>$\alpha=-1$, it is absolute function $g(z)=|z|$; </p>
<p>$\alpha$ is a small value, i.e. 0.01, it is <strong>Leaky ReLU</strong>;</p>
<p>$\alpha$ is a trainable parameter, it is <strong>PReLU (parametric ReLU)</strong>.</p>
<p>ReLU 会造成的低维数据的坍塌（collapse）。顾名思义，即是说，低维度的 feature 在通过 ReLU 的时候，这个 feature 会像塌方了一样，有一部分被毁掉了，或者说失去了。能恢复吗？能，但是基本无法百分百还原了。ReLU 这个东西，其实就是一个滤波器，只不过这个滤波器的作用域不是信号处理中的频域，而是特征域。那么滤波器又有什么作用呢？维度压缩，俗话说就是降维啦：如果我们有 m 个 feature 被送入 ReLU 层，过滤剩下 n 个（n&lt;m），这不就是相当于对 feature 的维度进行了压缩，使其从 m 维变为 n 维嘛。那么，为什么低维数据流经非线性激活层会发生坍塌（信息丢失），而高维数据就不会呢？维度低的 feature，分布到 ReLU 的激活带上的概率小，因此经过后信息丢失严重，甚至可能完全丢失。而维度高的 feature，分布到 ReLU 的激活带上的概率大，虽然可能也会有信息的部分丢失，但是无伤大雅，大部分的信息仍然得以保留。所谓留得青山在，不愁没柴烧嘛。更何况被 ReLU 截杀的信息，可能只是一些无用游民（冗余信息）。当信息无法流过 ReLU 时，该神经元的输出就会变为 0。而在反向传播的过程中，ReLU 对 0 值的梯度为 0，即发生了梯度消失，这将导致神经元的权重无法再通过梯度下降法进行更新，这种现象被称为特征退化。所以这个神经元相当于死掉了，丧失了学习能力。我们说，一旦神经元的输出陷入 0 值，就无法恢复了。</p>
<p>对于一个数据，利用非线性激活层对其进行激活，其实是从该数据的信息中提取出其潜在的稀疏性，但是这种提取的结果是否正确，就要分情况讨论了。对于一个 M 维的数据，我们可以将其看成是在 M 维空间中的一个 M 维流形（manifold）。而其中的有用信息，就是在该 M 维空间中的一个子空间（子空间的维度记为 N 维，N&lt;=M）中的一个 N 维流形。非线性激活层相当于压缩了这个 M 维空间的维度（还记得前面提过的维度压缩吗？）。若是该 M 维空间中的 M 维流形本来就不含有冗余信息（M=N），那么再对其进行维度压缩，必然导致信息的丢失。而维度低的数据其实就是这么一种情况：其信息的冗余度高的可能性本来就低，如果强行对其进行非线性激活（维度压缩），则很有可能丢失掉有用信息，甚至丢失掉全部信息（输出为全 0）。与非线性激活层不同的是，线性激活层并不压缩特征空间的维度。于是，我们得到了一条使用激活层的原则：对含有冗余信息的数据使用非线性激活（如 ReLU），对不含冗余信息的数据使用线性激活（如一些线性变换）。</p>
<p>由于冗余信息和非冗余信息所携带的有用信息是一样多的，因此在设计网络时，对内存消耗大的结构最好是用在非冗余信息上。根据以上的原则设计出来的结构，聪明的你想到了什么？ResNet。不得不赞叹 Kaiming He 的天才，ResNet 这东西，描述起来固然简单，但是对它的理解每深一层，就会愈发发现它的精妙及优雅，从数学上解释起来非常简洁，非常令人信服，而且直切传统痛点。ResNet 本质上就干了一件事：<strong>降低数据中信息的冗余度</strong>。具体说来，就是对非冗余信息采用了线性激活（通过 skip connection 获得无冗余的 identity 部分），然后对冗余信息采用了非线性激活（通过 ReLU 对 identity 之外的其余部分进行信息提取 / 过滤，提取出的有用信息即是残差）。由于 identity 之外的其余部分的信息冗余度较高，因此在对其使用 ReLU 进行非线性激活时，丢失的有用信息也会较少，ReLU 层输出为 0 的可能性也会较低。这就降低了在反向传播时 ReLU 的梯度消失的概率，从而便于网络的加深，以大大地发挥深度网络的潜能。</p>
<p><strong>Softmax</strong> </p>
<p>Softmax is always used as output layer of multi-classification models, which can be naturally represented as probability distribution of $n$ different values.<br>$$<br>g(z) = \frac{e^{z_i}}{\sum_{i=0}^n e^{z_i}}<br>$$<br>Softmax can solve overflow and underflow problems. The value can’t be changed if input vectors minus or plus a scalar. Thus, a simple method is $x = x - \max_i x_i$ then do softmax.</p>
<p>An interesting Chinese post: <a href="https://zhuanlan.zhihu.com/p/45014864" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45014864</a></p>
<p><strong>Softplus</strong></p>
<p>It is a smooth version of ReLu. However, its performance is not better than ReLu.</p>
<p><strong>Maxout</strong></p>
<p>Actually Maxout is not a fixed function, however, it’s a piecewise linear function which can fit any convex function. We can regard Maxout as an layer which is similar to pooling layer and conv layer. $k$ is a hyper-parameter in Maxout,which is like $p$ in dropout.</p>
<p>i.e. $k=5$ </p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/20160103165828920.png" alt="maxout"></p>
<p>The Maxout layer has 5 neurons so that parameters increase $k=5$ folds, and the output is $max(z_1,z_2,z_3,z_4,z_5)$.</p>
<p><strong>Radial Basis Function (RBF)</strong></p>
<p>$h_i=e^{-\frac{1}{\sigma_i ^ 2}||W_{:,i}-x||}$ It is rarely used in NNs because most x can be mapped to zero, which is difficult to optimize in training.</p>
<h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><p>在一定程度上限制了梯度的波动，从而降低了参数的搜索空间，因此相当于降低了模型的复杂度，所以提高了泛化能力.</p>
<h5 id="L1-L2-Regularization"><a href="#L1-L2-Regularization" class="headerlink" title="L1/L2 Regularization"></a>L1/L2 Regularization</h5><p>L1/L2 regularization is like a priori which limits distribution of parameters, so it can reduce model complexity. Meanwhile, if one feature has a very high weight and prediction is very close to ground truth, the loss would be huge due to L1/L2 term, which avoids high weights of one or several features. </p>
<p>When priori is Laplace distribution, the regularization term is L1 from; When priori is Gaussian distribution, the regularization term is L2 term. We know that $p(w=0)$ is highest in Laplace distribution and $p(w \rightarrow 0)$ is highest in Gaussian distribution. More interesting ideas in this Chinese <a href="https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&mid=2247484454&idx=1&sn=b3404eefaa68a78b770adb092d2fb48f&chksm=fb39a12dcc4e283b132138583ecd9848aa175b4cffd4036be07a2e132cb616e18ce8fe8c9adb&token=1151312247&lang=zh_CN&scene=21#wechat_redirect" target="_blank" rel="noopener">post</a>!</p>
<p>L1 regularization is sum of absolute values of all weights, which is marked as $||w||_1=\sum|w_i|$. L1 regularization can make some $w_i$ zero which leads to sparse matrix of weights. </p>

$$
\begin{align}
L &= L_0 + \frac{\lambda}{n} \sum_{w}|w|\\
\frac{\partial L}{\partial w}  &= \frac{\partial L_0}{\partial w} + \frac{\lambda}{n}sgn(w) \\
w &:= w - \alpha*\frac{\partial L}{\partial w} \ (where \ \alpha>0)\\
  &:= w - \alpha * \frac{\partial L_0}{\partial w} - \alpha * \frac{\lambda}{n}sgn(w) \\
\end{align}
$$



<p>From above equation, when $w$ is negative, updated $w$ will be greater; when $w$ is positive, updated $w$ will be smaller. Obviously, $w$ will move to zero. L1 regularization leads weights sparsity, which is important for online learning because sparsity can reduce memory and time of prediction.</p>
<p>L2 regularization is sum of square values of all weights, which is marked as $||w||_2=\sum w_i^2$. L2 regularization can make some $w_i$ approach to zero but not zero, which can prevent models from overfitting.</p>

$$
\begin{align}
L &= L_0 + \frac{\lambda}{2n} \sum_{w}w^2\\
\frac{\partial L}{\partial w}  &= \frac{\partial L_0}{\partial w} + \frac{\lambda}{n}w \\
w &:= w - \alpha*\frac{\partial L}{\partial w} \ (where \ \alpha>0)\\
  &:= w - \alpha * \frac{\partial L_0}{\partial w} - \alpha * \frac{\lambda}{n}w \\
  &:= w(1-\alpha * \frac{\lambda}{n}) - \alpha * \frac{\partial L_0}{\partial w}
\end{align}
$$


<p>From above equation, $(1-\alpha * \frac{\lambda}{n})&lt;1$, so $w$ will be reduced dramatically.</p>
<h5 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h5><p>With deep layers of NNs, the input data distribution before each layer will change, which is “Internal Covariate Shift”. That leads to slow convergence and gradient vanishing (because the distribution will be approaching to boundary of activation function).</p>
<p>A detail Chinese post : <a href="https://zhuanlan.zhihu.com/p/43200897" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/43200897</a></p>
<p>BN solves <strong>Internal Covariate Shift</strong> and makes all input data feeding in each layer same distribution.</p>
<p>In training phase, BN uses mini-batch data to compute mean and variance of $x_i$, so it’s normalization of single neuron.</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191115210001924.png" alt="Batch Normalization"></p>
<p>Re-sacling invariant: normalization doesn’t change outputs of activation function.</p>
<blockquote>
<p>为了解决神经元输入分布偏移的情况，对每个神经元的带权输入（一个mini-batch上）进行标准化，把发生偏移的带权输入拉回到同一分布上。首先这样做解决了上述中第一个分布发生变化的问题，使得每个神经元都会适当的激活，同时标准化使得带权输入分布在0附近更容易激活神经元解决梯度消失问题。但只做标准化容易把之前学习到的特征丢弃掉，这时候就引入了伸缩因子和平移因子（这两个参数是需要学习的），相当于对标准化后的带权输入又做了个线性变换。这样使得所有神经元带权输入都有一个同一的分布，但又保持了相对差异。</p>
</blockquote>
<p>这就是Batch Normalization强大的地方，如果只做normalize在某些情况下会出现问题，比如对象是Sigmoid函数的output，而且output是分布在Sigmoid函数的两侧，normalize会强制把output分布在Sigmoid函数的中间的非饱和区域，这样会导致这层网络所学习到的特征分布被normalize破坏。而上面算法的最后一步，scale and shift可以令零均值单位方差的分布（normalize之后的分布）通过调节gamma和beta变成任意更好的分布（对于喂给下一层网络来说）。因为这个gamma和beta是在训练过程中可以学习得到参数。最极端的情况就是当gamma = sqrt(var(x)) 和 beta = mean(x)的时候，就是题主所说的“打回原形”了，这种原来的论文中，Sergey说的是至少能够使特征分布回到normalize之前的分布，并不是每一层学习到的gamma和beta都会抵消之前的normalize的操作。我的理解是完整的BN通过normalize和scale &amp; shift两步的操作提供更高的flexibility，对于每层的output既可以是零均值单位方差的分布，也可以是分布于Sigmoid两端饱和区域的分布，或者其他任意的分布。</p>
<p>More normalization: Layer Normalization/Group Normalization/Weight Normalization/Cosine Normalization/ $SELU$<sup><a href="https://arxiv.org/abs/1706.02515" target="_blank" rel="noopener">1</a>  <a href="https://zhuanlan.zhihu.com/p/27362891" target="_blank" rel="noopener">2</a></sup></p>
<p><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">Why is BN so powerful?</a></p>
<p>那么BN有效的真正原因到底是什么呢？这还要从深度网络的损失曲面（Loss Surface）说起，在深度网络叠加大量非线性函数方式来解决非凸复杂问题时，损失曲面形态异常复杂，大量空间坑坑洼洼相当不平整，也有很多空间是由平坦的大量充满鞍点的曲面构成，训练过程就是利用SGD在这个复杂平面上一步一步游走，期望找到全局最小值，也就是曲面里最深的那个坑。所以在SGD寻优时，在如此复杂曲面上寻找全局最小值而不是落入局部最小值或者被困在鞍点动弹不得，可想而知难度有多高。</p>
<p>有了损失曲面的基本概念，我们回头来看为何BN是有效的。研究表明，BN真正的用处在于：通过上文所述的Normalization操作，使得网络参数重整（Reparametrize），它对于非线性非凸问题复杂的损失曲面有很好的平滑作用，参数重整后的损失曲面比未重整前的参数损失曲面平滑许多。</p>
<p>An interesting Chinese <a href="https://www.jiqizhixin.com/articles/2018-08-29-7" target="_blank" rel="noopener">post</a> of normalization!</p>
<p>Why can’t BN be used with dropout or other regularization methods?</p>
<blockquote>
<p><strong>我们从二者的基本出发点看，batch norm本质是控制相空间的体积，使得在映射过程中保证信号可以不衰减不爆炸，就是Jacobian的特征值的分布要合理，让系统处于一个接近临界点的状态；dropout的作用是保证系统在扰动下稳定或鲁棒，对输入信号或者系统参数系统结构的扰动不带来性能的显著恶化。定性的看，batch norm要保证信息流深，dropout要保证信息流阔。从这个角度看，二者匹配的就分别是深的网络和宽的网络，或者说解决的是这两类结构可能存在的缺陷，深的网络需要信息流足够深从而可以穿透网络，宽的网络需要信息流在相当的一个参数空间体积下都能有一定流量，否则好的解空间就容易被淹没或者错过。实际上二者的作用有相似和互补，但又有差异，这种差异使得二者分别和现有CNN网络的两部分结构匹配起来更合理一些，但并不是说不能混合起来用，BN对于全连接的部分也同样有效，dropout对CNN也一样有改善，甚至我觉得dropout应该持续作用于CNN部分，这种约束对于保证系统的鲁棒性防止过拟合会很有效的，对防范对抗攻击也会起作用，直观上使用了dropout的系统应该landscape更平缓一些。</strong></p>
<p>source：<a href="https://www.zhihu.com/question/294560934/answer/511857321" target="_blank" rel="noopener">https://www.zhihu.com/question/294560934/answer/511857321</a></p>
</blockquote>
<p>A Chinese post: <a href="https://zhuanlan.zhihu.com/p/61725100" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61725100</a> </p>
<p><a href="https://arxiv.org/abs/1801.05134" target="_blank" rel="noopener">Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift</a></p>
<p>The key idea is variance shift. Dropout will randomly drop neurons, which makes variance change. However, BN is trying to keep variance stable. Obviously, that paradox leads variance shift and it will be increasingly serious with deeper and deeper layers.</p>
<p>In the other hand, dropout makes we cannot compute mean and variance due to we don’t have integrated data and some of that will be randomly dropped.</p>
<p>One solution is put Dropout behind BN and another is Gaussian Dropout. But combination of BN and Dropout is not far better than only BN.</p>
<p><strong>Advantages</strong></p>
<ul>
<li>Speed up convergence</li>
<li>Larger learning rate</li>
<li>Lower requirement of parameter initialization</li>
<li>Avoid gradient vanishing</li>
<li>Introduce random noise as regularization to get better generalization</li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li><p>Poor performance on small batch size</p>
<ul>
<li>batch size 设置得较小训练出来的模型相对大batch size训练出的模型泛化能力更强，在测试集上的表现更好，而太大的batch size往往不太Work，而且泛化能力较差。但是背后是什么原因造成的，目前还未有定论，持不同看法者各持己见。</li>
<li>can’t apply on <strong>online-learning</strong>, because online models update parameters in single instance without mini-batch structure</li>
</ul>
</li>
<li><p>no application on dynamical networks, such as RNN, because length of their inputs is variant</p>
<ul>
<li>对于RNN来说，尽管其结构看上去是个静态网络，但在实际运行展开时是个动态网络结构，因为输入的Sequence序列是不定长的，这源自同一个Mini-Batch中的训练实例有长有短。对于类似RNN这种动态网络结构，BN使用起来不方便，因为要应用BN，那么RNN的每个时间步需要维护各自的统计量，而Mini-Batch中的训练实例长短不一，这意味着RNN不同时间步的隐层会看到不同数量的输入数据，而这会给BN的正确使用带来问题。假设Mini-Batch中只有个别特别长的例子，那么对较深时间步深度的RNN网络隐层来说，其统计量不方便统计而且其统计有效性也非常值得怀疑。另外，如果在推理阶段遇到长度特别长的例子，也许根本在训练阶段都无法获得深层网络的统计量。综上，在RNN这种动态网络中使用BN很不方便，而且很多改进版本的BN应用在RNN效果也一般。</li>
</ul>
</li>
<li><p>对于有些像素级图片生成任务来说，BN效果不佳.对于图片分类等任务，只要能够找出关键特征，就能正确分类，这算是一种粗粒度的任务，在这种情形下通常BN是有积极效果的。但是对于有些输入输出都是图片的像素级别图片生成任务，比如图片风格转换等应用场景，使用BN会带来负面效果，这很可能是因为在Mini-Batch内多张无关的图片之间计算统计量，弱化了单张图片本身特有的一些细节信息。</p>
</li>
<li><p>训练时和推理时统计量不一致</p>
<ul>
<li><p>对于BN来说，采用Mini-Batch内实例来计算统计量，这在训练时没有问题，但是在模型训练好之后，在线推理的时候会有麻烦。因为在线推理或预测的时候，是单实例的，不存在Mini-Batch，所以就无法获得BN计算所需的均值和方差，一般解决方法是采用训练时刻记录的各个Mini-Batch的统计量的数学期望，以此来推算全局的均值和方差，在线推理时采用这样推导出的统计量。虽说实际使用并没大问题，但是确实存在训练和推理时刻统计量计算方法不一致的问题。</p>
</li>
<li><p>对于BN，在训练时，是对每一批的训练数据进行归一化，也即用每一批数据的均值和方差。而在测试时，比如进行一个样本的预测，就并没有batch的概念，因此，这个时候用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。</p>
<p>对于BN，当一个模型训练完成之后，它的所有参数都确定了，包括均值和方差，gamma和beta。BN训练时为什么不用全量训练集的均值和方差呢？因为用全量训练集的均值和方差容易过拟合，对于BN，其实就是对每一批数据进行归一化到一个相同的分布，而每一批数据的均值和方差会有一定的差别，而不是用固定的值，这个差别实际上能够增加模型的鲁棒性，也会在一定程度上减少过拟合。也正是因此，BN一般要求将训练集完全打乱，并用一个较大的batch值，否则，一个batch的数据无法较好得代表训练集的分布，会影响模型训练的效果。</p>
</li>
</ul>
</li>
</ul>
<p>BN can be put before activation function (original paper) or behind the function (some researches show that models get better performance).</p>
<p><strong>Variants of BN</strong></p>
<ul>
<li>Layer Normalization<ul>
<li>all neurons in the same layer as statistical area</li>
</ul>
</li>
<li>Instance Normalization<ul>
<li>CNN中将同一卷积层中每个卷积核对应的输出通道单独作为自己的统计范围</li>
</ul>
</li>
<li>Group Normalization<ul>
<li>对CNN中某一层卷积层的输出或者输入通道进行分组，在分组范围内进行统计</li>
</ul>
</li>
</ul>
<h5 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h5><p>Dropout is a popular regularization in deep learning. It can be viewed as dropping partial neurons with probability $p$ in training phase and outputs of those dropped neurons are zero. <strong>It’s ensemble of some sub-nets so that can reduce overfitting and increase generalization.</strong></p>
<p>Dropout is similar with average of multiple DNNs, so it has effect of vote.</p>
<p>When some neurons in hidden layers are dropped, fully connected networks get sparsity so that reducing collaborative effect of different features. In other words, some features may be dependent on other features (nodes), so NNs can be more robust by dropout which effectively organizes that some features are available only when some specific features survive.</p>
<h4 id="Normalization-and-Standardization"><a href="#Normalization-and-Standardization" class="headerlink" title="Normalization and Standardization"></a>Normalization and Standardization</h4><p><strong>Normalization</strong></p>
<p>Mapping data into a specific interval, usually $[-1,1]$, $[0,1]$.</p>
<ul>
<li>Min-Max Normalization</li>
</ul>
<p>$$<br>x’=\frac{x-min(x)}{max(x)-min(x)}<br>$$</p>
<p><strong>Standardization</strong></p>
<p>Mapping data into normal distribution.<br>$$<br>x’=\frac{x-\mu}{\sigma}<br>$$<br>Normalization and Standardization can improve model precision(normalization) and speed up model convergence(standardization).</p>
<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><h5 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h5><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Positive</th>
<th align="center">Negative</th>
</tr>
</thead>
<tbody><tr>
<td align="center">True</td>
<td align="center">TP</td>
<td align="center">TN</td>
</tr>
<tr>
<td align="center">False</td>
<td align="center">FP</td>
<td align="center">FN</td>
</tr>
</tbody></table>
<h5 id="Accuracy-Precision-Recall-F1"><a href="#Accuracy-Precision-Recall-F1" class="headerlink" title="Accuracy / Precision / Recall / F1"></a>Accuracy / Precision / Recall / F1</h5><p>$ACC=\frac{TP+TN}{TP+TN+FP+FN}$</p>
<p>$Precision=\frac{TP}{TP+FP}$</p>
<p>$Recall=\frac{TP}{TP+FN}$</p>
<p>$\frac{2}{F1}=\frac{1}{P}+\frac{1}{R}$</p>
<h5 id="AUC-Area-Under-the-Receiver-Operating-Characteristics"><a href="#AUC-Area-Under-the-Receiver-Operating-Characteristics" class="headerlink" title="AUC (Area Under the Receiver Operating Characteristics)"></a>AUC (<strong>Area Under the</strong> Receiver Operating Characteristics)</h5><p><img src="https://miro.medium.com/max/722/1*pk05QGzoWhCgRiiFbz-oKQ.png" alt="AUC"></p>
<p>Randomly choosing one sample, s1, from class A and one sample, s2, from class B, then predicting them by your classifier. P1 is the probability of your model predicting s1 as class A; P2 is the probability of model predicting s2 as class B. The probability of P1 &gt; P2 is AUC.</p>
<p>它和Wilcoxon-Mann-Witney Test是等价的。这个等价关系的证明留在下篇帖子中给出。而Wilcoxon-Mann-Witney Test就是测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。有了这个定义，我们就得到了另外一中计 算AUC的办法：得到这个概率。<br><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116013843143.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116013910117.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116013921388.png" alt></p>
<h4 id="Search-of-Hyperparameters"><a href="#Search-of-Hyperparameters" class="headerlink" title="Search of Hyperparameters"></a>Search of Hyperparameters</h4><ul>
<li><p>Grid Search</p>
</li>
<li><p>Random Search</p>
</li>
<li><p>Bayesian Optimization</p>
</li>
</ul>
<p>More details in this <a href="http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html" target="_blank" rel="noopener">post</a>!</p>
<h4 id="Information-Theory"><a href="#Information-Theory" class="headerlink" title="Information Theory"></a>Information Theory</h4><p>Self-information: $I(x)=-logP(x)$</p>
<p>Information-entropy: $H(X)=E_{X \in P}[I(x)]=-\sum_{x \in X} P(x)logP(x)$</p>
<p>Kullback-Leibler divergence: $D_P(Q)=E_{X \in P}[log\frac{P(x)}{Q(x)}]=\sum_{x \in X}P(x)log \frac{P(x)}{Q(x)}$</p>
<p>Cross-entropy: $H_P(Q)=-E_{X \in P}logQ(x)=-\sum_{x \in X}P(x)log Q(x)$</p>
<p>$H_P(Q)=H(P)+D_P(Q)$</p>
<h3 id="Cost-Function-Loss-Function-and-Objective-Function"><a href="#Cost-Function-Loss-Function-and-Objective-Function" class="headerlink" title="Cost Function, Loss Function and Objective Function"></a>Cost Function, Loss Function and Objective Function</h3><p>Loss function is defined in single sample. Cost function is defined in whole dataset. In fact, you can use both loss function and cost function because they are same. Objective function is cost function plus regularization terms.</p>
<p>$loss=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))$ is also called empirical risk; $RegularizationTerm=\lambda R(f)$ is also called structural risk. Objective function is $Obj=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda R(f)$.</p>
<p>Common loss functions:</p>
<ul>
<li><p>Classification</p>
<ul>
<li><p>Log loss \ cross entropy</p>
<p>$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)} log \ h_\theta(x^{(i)})+(1-y^{(i)})log \ (1-h_\theta(x^{(i)}))]$</p>
</li>
<li><p>Focal loss</p>
<p><img src="https://img-blog.csdnimg.cn/20190719190148967.png" alt="Focal Loss"></p>
</li>
<li><p>KL divergence / Relative entropy</p>
<p>$L=D_{KL}(p|q)=\sum_x{p(x)}{\log \frac{p(x)}{q(x)}}$</p>
</li>
<li><p>Exponential loss (AdaBoost)</p>
<p>$L=e^{-y_if(x_i;w)}$</p>
</li>
<li><p>Hinge loss (SVM)</p>
<p>$L=max(0, 1-yf(x;w))$</p>
</li>
</ul>
</li>
<li><p>Regression</p>
<ul>
<li><p>MSE / Quadratic loss</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/1529558773906.png" alt="MSE"></p>
</li>
<li><p>MAE</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/1529558773392.png" alt="MAE"></p>
</li>
<li><p>Huber loss / Smooth Mean Absolute Error</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/1529558774147.png" alt="Huber Loss"></p>
</li>
<li><p>Smooth L1 Loss</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191117220354211.png" alt="Smooth L1 Loss"></p>
</li>
<li><p>Log cosh loss</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/1529558774452.png" alt="Log cosh loss"></p>
</li>
<li><p>Quantile loss</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/1529558775749.png" alt="Quantile Loss"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Optimizers"><a href="#Optimizers" class="headerlink" title="Optimizers"></a>Optimizers</h3><p>During the training process, we tweak and change the parameters (weights) of our model to try and minimize that loss function, and make our predictions as correct as possible. Optimizers tie together the loss function and model parameters by updating the model in response to the output of the loss function.</p>
<p><a href="https://leovan.me/cn/2018/02/optimization-methods-for-deeplearning/" target="_blank" rel="noopener">post1</a> <a href="http://ruder.io/optimizing-gradient-descent/index.html#fn3" target="_blank" rel="noopener">post2</a></p>
<h4 id="Gradient-Descent-GD"><a href="#Gradient-Descent-GD" class="headerlink" title="Gradient Descent (GD)"></a>Gradient Descent (GD)</h4><p>Gradient Descent is a way to minimize an objective function $J(\theta)$ parameterized by a model’s parameters $\theta \in R^d$ by updating the parameters in the opposite direction of the gradient of the objective function $\triangledown_\theta J(\theta)$ w.r.t. to the parameters. The learning rate $\eta$ determines the size of the steps we take to reach a local minimum.</p>
<p>$\theta:=\theta-\eta \frac{\partial J(\theta)}{\partial \theta}=\theta-\eta {\triangledown_\theta J(\theta)}$</p>
<h5 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h5><p>It’s also called vanilla gradient descent, which computes the gradient of the cost function for the entire training dataset: $\theta:=\theta-\eta \frac{\partial J(\theta)}{\partial \theta}$. As we need to calculate the gradients for whole dataset to update parameters once, batch gradient descent can be very slow and is intractable for datasets that don’t fit in memory. Batch gradient descent also doesn’t allow us to update models online, aka online learning.</p>
<h5 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h5><p>SGD updates a parameter for each training example: $\theta := \theta-\eta \triangledown_\theta J(\theta;x^{(i)};y^{(i)})$, so it is much faster and can be used to learn online. SGD performs frequent updates with a high variance that cause the objective function to fluctuate heavily. While batch gradient descent converges to the minimum of the basin the parameters are placed in, SGD’s fluctuation, on the one hand, enables it to jump to new and potentially better local minima. On the other hand, this ultimately complicates convergence to the exact minimum, as SGD will keep overshooting. However, it has been shown that when we slowly decrease the learning rate, SGD shows the same convergence behaviour as batch gradient descent, almost certainly converging to a local or the global minimum for non-convex and convex optimization respectively.</p>
<h5 id="Mini-Batch-Gradient-Descent"><a href="#Mini-Batch-Gradient-Descent" class="headerlink" title="Mini-Batch Gradient Descent"></a>Mini-Batch Gradient Descent</h5><p>Mini-Batch Gradient Descent is a trade-off of batch GD and SGD, which updates a parameter for every mini-batch of n training examples: </p>
<p>$\theta := \theta-\eta \triangledown_\theta J(\theta;x^{(i:i+n)};y^{(i:i+n)})$. </p>
<h5 id="Mini-Batch-Stochastic-Gradient-Descent"><a href="#Mini-Batch-Stochastic-Gradient-Descent" class="headerlink" title="Mini-Batch Stochastic Gradient Descent"></a>Mini-Batch Stochastic Gradient Descent</h5><p>It’s easy to think of this method. Mini-Batch SGD updates a parameter for one example in a mini-batch of n training examples. In fact, what we said SGD nowadays is Mini-Batch SGD which is much faster and performs very well. Mini-Batch SGD is absolutely one of most popular optimization algorithms of ML/DL, especially for large scale dataset.</p>
<h5 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h5><p>Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge.</p>
<p>Learning rate schedules try to adjust the learning rate during training by e.g. annealing, i.e. reducing the learning rate according to a pre-defined schedule or when the change in objective between epochs falls below a threshold. These schedules and thresholds, however, have to be defined in advance and are thus unable to adapt to a dataset’s characteristics.</p>
<p>Additionally, the same learning rate applies to all parameter updates. If our data is sparse and our features have very different frequencies, we might not want to update all of them to the same extent, but perform a larger update for rarely occurring features.</p>
<p>Another key challenge of minimizing highly non-convex error functions common for neural networks is avoiding getting trapped in their numerous suboptimal local minima. The difficulty arises in fact not from local minima but from saddle points, i.e. points where one dimension slopes up and another slopes down. These saddle points are usually surrounded by a plateau of the same error, which makes it notoriously hard for SGD to escape, as the gradient is close to zero in all dimensions.</p>
<h4 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h4><p>SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another, which are common around local optima. In these scenarios, SGD oscillates across the slopes of the ravine while only making hesitant progress along the bottom towards the local optimum. Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction $\gamma$ of the update vector of the past time step to the current update vector: </p>
<p>$v_t=\gamma v_{t-1} + \eta \triangledown_\theta J(\theta)$</p>
<p>$\theta := \theta - v_t$</p>
<p>The momentum term $\gamma$ is usually set to 0.9. The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.</p>
<h4 id="Nesterov-accelerated-gradient-NAG"><a href="#Nesterov-accelerated-gradient-NAG" class="headerlink" title="Nesterov accelerated gradient (NAG)"></a>Nesterov accelerated gradient (NAG)</h4><p>as we reach the minima i.e the lowest point on the curve ,the momentum is pretty high and it doesn’t knows to slow down at that point due to the high momentum which could cause it to miss the minima entirely and continue movie up. </p>
<p>NAG is a way to give our momentum term this kind of prescience. We know that we will use our momentum term $\gamma v_{t-1}$ to move the parameters $\theta$. Computing $\theta-\gamma v_{t-1}$ thus gives us an approximation of the next position of the parameters which gives us a rough idea where our parameters are going to be. We can now effectively look ahead by calculating the gradient not w.r.t. to our current parameters $\theta$ but w.r.t. the approximate future position of our parameters:</p>
<p>$v_t=\gamma v_{t-1} + \eta \triangledown_\theta J(\theta - \gamma v_{t-1})$</p>
<p>$\theta := \theta - v_t$</p>
<h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><p>Adagrad is an algorithm for gradient-based optimization that does just this: It adapts the learning rate to the parameters, performing smaller updates (i.e. low learning rates) for parameters associated with frequently occurring features, and larger updates (i.e. high learning rates) for parameters associated with infrequent features. For this reason, it is well-suited for dealing with sparse data. </p>
<p>$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\epsilon+\sum_{i=0}^t g_t^2}}\cdot g_t $</p>
<p>One of Adagrad’s main benefits is that it eliminates the need to manually tune the learning rate. Most implementations use a default value of 0.01 and leave it at that.</p>
<p>Adagrad’s main weakness is its accumulation of the squared gradients in the denominator: Since every added term is positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge.</p>
<h4 id="AdaDelta"><a href="#AdaDelta" class="headerlink" title="AdaDelta"></a>AdaDelta</h4><p>Adadelta is an extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate. Instead of accumulating all past squared gradients, Adadelta restricts the window of accumulated past gradients to some fixed size w.</p>
<p>$v_t=\gamma <em>v_{t-1}+(1-\gamma)</em>g_t^2$</p>
<p>$\triangle \theta_t = \frac{\eta}{\sqrt{v_t+\epsilon}}*g_t$</p>
<p>$\eta_t=\gamma \eta_{t-1}+(1-\gamma) \triangle \theta_t^2$</p>
<p>$\theta_{t+1}=\theta_{t}-\frac{\eta_{t}}{\sqrt{v_t+\epsilon}}*g_t$</p>
<h4 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h4><p>RMSprop and Adadelta have both been developed independently around the same time stemming from the need to resolve Adagrad’s radically diminishing learning rates. RMSprop in fact is identical to the first update vector of Adadelta that we derived above:</p>
<p>$v_t=\gamma <em>v_{t-1}+(1-\gamma)</em>g_t^2$</p>
<p>$\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{v_t+\epsilon}}*g_t$</p>
<p>RMSprop as well divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests $\gamma$ to be set to 0.9, while a good default value for the learning rate $\eta$ is 0.001.</p>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p>Adaptive Moment Estimation (Adam) is another method that computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients $v_t$ like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients $m_t$, similar to momentum. Whereas momentum can be seen as a ball running down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the error surface.</p>
<p>$m_t=\beta_1 m_{t-1} + (1-\beta_1)g_t$</p>
<p>$v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2$</p>
<p>$\hat{m_t}=\frac{m_t}{1-\beta_1^t}$</p>
<p>$\hat{v_t}=\frac{v_t}{1-\beta_2^t}$</p>
<p>$\theta_{t+1}=\theta_t - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon}\hat{m_t}=\theta_t - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon}(\beta_1\hat{m_{t-1}}+\frac{(1-\beta_1)g_t}{1-\beta_1^t})$</p>
<p>The authors propose default values of 0.9 for $\beta_1$, 0.999 for $\beta_2$, and $10^{-8}$ for $\epsilon$. Adam can be viewed as a combination of RMSprop and momentum.</p>
<p>Adam is good, but there are still some problems. Some researches are <a href="https://arxiv.org/abs/1712.07628" target="_blank" rel="noopener">Improving Generalization Performance by Switching from Adam to SGD</a>.</p>
<h4 id="AdaMax"><a href="#AdaMax" class="headerlink" title="AdaMax"></a>AdaMax</h4><p>$u_t=max(\beta_2 \cdot v_{t-1}, |g_t|)$</p>
<p>$\theta_{t+1}=\theta_t - \frac{\eta}{u_t} \hat{m_t}$</p>
<p>Good default values are given $\eta=0.002$, $\beta_1=0.9$, and $\beta_2=0.999$. </p>
<h4 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h4><p>Nadam (Nesterov-accelerated Adaptive Moment Estimation) thus combines Adam and NAG. Nadam = Adam + Nesterov.</p>
<p>$m_t=\beta_1 m_{t-1} + (1-\beta_1)g_t$</p>
<p>$v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2$</p>
<p>$\hat{m_t}=\frac{m_t}{1-\beta_1^t}$</p>
<p>$\hat{v_t}=\frac{v_t}{1-\beta_2^t}$</p>
<p>$\theta_{t+1}=\theta_t - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon}(\beta_1\hat{m_t}+\frac{(1-\beta_1)g_t}{1-\beta_1^t})$</p>
<h4 id="AMSGrad"><a href="#AMSGrad" class="headerlink" title="AMSGrad"></a>AMSGrad</h4><p>The exponential moving average of past squared gradients as a reason for the poor generalization behaviour of adaptive learning rate methods. Recall that the introduction of the exponential average was well-motivated: It should prevent the learning rates to become infinitesimally small as training progresses, the key flaw of the Adagrad algorithm. However, this short-term memory of the gradients becomes an obstacle in other scenarios.</p>
<p>$m_t=\beta_1 m_{t-1} + (1-\beta_1)g_t$</p>
<p>$v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2$</p>
<p>$\hat{v_t}=max(\hat{v}_{t-1},v_t)$</p>
<p>$\theta_{t+1}=\theta_t - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon}m_t$</p>
<h4 id="Follow-the-Regularized-Leader-FTRL"><a href="#Follow-the-Regularized-Leader-FTRL" class="headerlink" title="Follow the Regularized Leader (FTRL)"></a>Follow the Regularized Leader (FTRL)</h4><p><a href="http://vividfree.github.io/机器学习/2015/12/05/understanding-FTRL-algorithm" target="_blank" rel="noopener">http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/05/understanding-FTRL-algorithm</a></p>
<p>在工业界，越来越多的业务需要大规模机器学习，不单参与训练的数据量大，模型特征量的规模也大。例如点击率预估，训练数据量在TB量级，特征量在亿这个量级，业内常用LR（Logistic Regression）和FM（Factorization Machines）为点击率预估建模。对LR、FM这类模型的参数学习，传统的学习算法是batch learning算法，它无法有效地处理大规模的数据集，也无法有效地处理大规模的在线数据流。这时，有效且高效的online learning算法显得尤为重要。</p>
<p>SGD算法是常用的online learning算法，它能学习出不错的模型，但学出的模型不是稀疏的。为此，学术界和工业界都在研究这样一种online learning算法，它能学习出有效的且稀疏的模型。FTRL（Follow the Regularized Leader）算法正是这样一种算法，它由Google的H. Brendan McMahan在2010年提出的，作者后来在2011年发表了一篇关于FTRL和AOGD、FOBOS、RDA比较的论文，2013年又和Gary Holt, D. Sculley, Michael Young等人发表了一篇关于FTRL工程化实现的论文。如论文的内容所述，FTRL算法融合了RDA算法能产生稀疏模型的特性和SGD算法能产生更有效模型的特性。它在处理诸如LR之类的带非光滑正则化项（例如1范数，做模型复杂度控制和稀疏化）的凸优化问题上性能非常出色，国内各大互联网公司都已将该算法应用到实际产品中。</p>
<img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190711218.png" style="zoom:150%;">

<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190725165.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190735241.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190745096.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190820127.png" alt></p>
<p>Equation above can be equation below which is SGD equation:</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116190900745.png" alt></p>
<p>In conclusion, in equation of FTRL left side is equal to SGD and right side is L1 norm which can make sparse solutions.</p>
<p>SGD引入L1实际上不太容易产生稀疏解，但是按照上面的推导来看ftrl就是在SGD的基础上引入了L1.在GD算法下，L1正则化通常能得到更加稀疏的解；可是在SGD算法下模型迭代并不是沿着全局梯度下降，而是沿着某个样本的梯度进行下降，这样即使是L1正则也不一定能得到稀疏解。在后面的优化算法中，稀疏性是一个主要追求的目标。</p>
<p><a href="https://courses.cs.washington.edu/courses/cse599s/12sp/scribes/Lecture8.pdf" target="_blank" rel="noopener">https://courses.cs.washington.edu/courses/cse599s/12sp/scribes/Lecture8.pdf</a></p>
<p><a href="http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf" target="_blank" rel="noopener">http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf</a></p>
<p>不论怎样，简单截断、TG、FOBOS都还是建立在SGD的基础之上的，属于梯度下降类型的方法，这类型方法的优点就是精度比较高，并且TG、FOBOS也都能在稀疏性上得到提升。但是有些其它类型的算法，例如RDA从另一个方面来求解Online Optimization并且更有效地提升了特征权重的稀疏性。RDA（Regularized Dual Averaging）是微软十年的研究成果。</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116191751785.png" alt="FOBOS, RDA and FTRL"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116191804483.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116191913836.png" alt></p>
<p>有效稀疏：所谓有效稀疏，就是要避免某个权重还没训练充分就被稀疏成0，这时候，累计梯度的作用就出来了，这保证了某权重被训练到一定程度了，才开始稀疏。SGD为啥不行？稀疏手段还是次要的，主要还是没有做有效稀疏，而有效稀疏的关键是累计梯度。</p>
<h4 id="Lookahead"><a href="#Lookahead" class="headerlink" title="Lookahead"></a>Lookahead</h4><p><a href="https://arxiv.org/abs/1907.08610v1" target="_blank" rel="noopener">https://arxiv.org/abs/1907.08610v1</a></p>
<h4 id="Newton’s-method-and-Quasi-Newton-methods"><a href="#Newton’s-method-and-Quasi-Newton-methods" class="headerlink" title="Newton’s method and Quasi-Newton methods"></a>Newton’s method and Quasi-Newton methods</h4><h5 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h5><p><a href="https://en.wikipedia.org/wiki/Newton' target=" _blank" rel="noopener" s_method">Newton’s method</a> finds next position by tangent line of current position.</p>
<p>$x_{n+1}=x_{n}-\frac{f(x_{n})}{f’(x_n)}$</p>
<p>Newton’s method is faster than gradient descent because it is second convergence. However, Newton’s method needs to compute inverse matrix of Hessian matrix of objective function, so the computation is very complex.</p>
<p>$\theta := \theta - H^{-1}J(\theta)$</p>
<h5 id="Quasi-Newton-methods"><a href="#Quasi-Newton-methods" class="headerlink" title="Quasi-Newton methods"></a>Quasi-Newton methods</h5><p>Fitting inverse matrix of Hessian matrix by positive matrix</p>
<ul>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><h4 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h4><p>The most basic regression model, $y=w^Tx+b$.</p>
<h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><p>LR is initially proposed for binary classification, i.e. $y_1$ and $y_2$.</p>

$$
\begin{align}
p(y=y_1|x) &= \frac{p(x|y_1)p(y_1)}{p(x)} \\
&= \frac{p(x|y_1)p(y_1)}{p(x|y_1)p(y_1)+p(x|y_2)p(y_2)} \\
&= \frac{1}{1+\frac{p(x|y_2)p(y_2)}{p(x|y_1)p(y_1)}} \\
\end{align}
\\ Assumed \ ln\frac{p(x|y_1)p(y_1)}{p(x|y_2)p(y_2)}=a, \ so \ p(y=y_1|x)=\frac{1}{1+e^{-a}}
$$


<p>We know that LR formulation is as following:</p>
<p>$h_{\theta}=\frac{1}{1+e^{-z}}$</p>
<p>$z=\theta^Tx+b$</p>
<p>The likelihood function is $L(\theta)=\prod_{i=1}^N h_\theta(x)^{y_i}(1-h_\theta(x))^{1-y_i}$.</p>
<p>Thus, loss function is $J(\theta)=-L(\theta)$.</p>
<h4 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h4><p><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank" rel="noopener">KNN</a> is a non-parametric method used for classification and regression. The lower the k is, the more sensitive the model is.</p>
<h4 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h4><p>The key idea of SVM is maximizing margins. Margin is the distance between hyper-plane and support vectors. Support vectors are those nearest points to hyper-plane.</p>
<p>Hyper-plane: $w^Tx+b=0$</p>
<p>Functional margin: $\hat{\gamma} = |w^Tx+b| = y(w^Tx+b)$</p>
<p>Minimum of functional margin in all samples: $\hat{\gamma}=min \hat{\gamma_i}$</p>
<p>Geometric margin: $\gamma = \frac{\hat{\gamma}}{||w||}$</p>
<p>In SVM, we hope maximize the margin, so</p>

$$
\max_{w,b} \ \gamma \\
s.t. y_i(\frac{w^Tx+b}{||w||}) \ge \gamma, i=1,2,\cdots,N \\
\Rightarrow \max_{w,b} \frac{\hat{\gamma}}{||w||} \\
s.t. y_i(w^Tx_i+b) \ge \hat{\gamma}, i=1,2,\cdots,N
$$


<p>Functional margin is minimum distance between sample point and hyper-plane. If making functional margin be $1$, distance between other points and hyper-plane is more than $1$. So,</p>

$$
\max_{w,b} \frac{1}{||w||} \\
\Rightarrow \min_{w,b} \frac{1}{2}||w||^2 \\
s.t. y_i(w^Tx_i+b)-1 \ge 0, i=1,2,\cdots,N \\
L(w,b,\alpha) = \frac{1}{2}||w||^2+\alpha_i \sum_{i=1}^N[-y_i(w^Tx+b)+1]=\frac{1}{2}||w||^2-\sum_{i=1}^N \alpha_iy_i(w^Tx_i+b)+\sum_{i=1}^N \alpha_i \\
\because \alpha_i \ge 0 \\
\therefore \max_\alpha L(w,b,\alpha)=\frac{1}{2}||w||^2 \\
\therefore \min_{w,b} \frac{1}{2}||w||^2 \Rightarrow \min_{w,b}\max_\alpha L(w,b,a) \\
According \ to \ Lagrange \ duality \ problem, 
\min_{w,b}\max_\alpha L(w,b,\alpha) \Rightarrow \max_\alpha \min_{w,b} L(w,b,\alpha)\\
\min_{w,b}L(w,b,\alpha) \Rightarrow \triangledown_wL(w,b,\alpha) = w-\sum_{i=1}^N\alpha_iy_ix_i = 0 \ and \ \triangledown_bL(w,b,\alpha)=\sum_{i=1}^N\alpha_iy_i=0 \\
w = \sum_{i=1}^N \alpha_iy_ix_i \\
\sum_{i=1}^N\alpha_iy_i=0 \\
\therefore \min_{w,b}L(w,b,\alpha) = -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j + \sum_{i=1}^N \alpha_i \\
Then, \ \max_\alpha -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j + \sum_{i=1}^N \alpha_i, s.t. \sum_{i=1}^N \alpha_iy_i=0 \ and \ \alpha_i \ge 0\\
\Rightarrow \min_\alpha \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j - \sum_{i=1}^N \alpha_i, s.t. \sum_{i=1}^N \alpha_iy_i=0 \ and \ \alpha_i \ge 0 \\
Computing \ \alpha^* \ by \ SMO \ algorithm \\
b^* = y_j - \sum_{i=1}^N \alpha_i^*y_ix_i^Tx_j \\
hyper-plane \Rightarrow \sum_{i=1}^N \alpha_i^*y_ix^Tx_i + b^* = 0 \\
f(x) = sign(\sum_{i=1}^N \alpha_i^*y_ix^Tx_i + b^*)
$$


<p>Above content is soft margin SVM which is used in linear classification. However, there’re usually some outliers in dataset, so the problem is about near-linear classification. We should use hard margin SVM which introduces a slack variable $\xi$ ($\xi \ge 0$), then constraint condition becomes $y_i(w^Tx_i+b) \ge 1-\xi_i$. The objective function is then modified to $\frac{1}{2}||w||^2+C \sum_{i=1}^N \xi_i$, where $C &gt; 0$ (penalty parameter). When $C$ is large, the penalty of misclassification becomes large; when $C$ is small, the penalty becomes small. $C$ Is like $\lambda$ in regularization and controls margins of model and importance of misclassified points. Hard margin SVM is computed in same way of soft margin SVM.</p>
<p>However, there are still some non-linear classification problem. It’s time to introduce kernel trick, which maybe one of coolest invitations in ML. </p>
<p>Kernel: linear kernel, polynomial kernel, Gaussian kernel, etc</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&mid=2247484795&idx=1&sn=895b56d7ad79e4dcbf73cea448167a55&chksm=fb39a070cc4e29661f72e2ccb78081dffff2c581963026a12b961276d6d9fe8a2bd8ce61cd24&token=1838236212&lang=zh_CN&scene=21#wechat_redirect" target="_blank" rel="noopener">SMO</a></p>
<h4 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h4><p><a href="https://en.wikipedia.org/wiki/Decision_tree" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Decision_tree</a></p>
<h5 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h5><p>Information gain is the metric of choosing and split features.</p>
<p>$Ent(D)=-\sum_{k=1}^{y}p_k \log_2p_k$</p>
<p>$Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)$ </p>
<p>ID3 chooses highest $Gain(D,a)$. </p>
<h5 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h5><p>$GainRatio(D,a)=\frac{Gain(D,a)}{IV(a)}$</p>
<p>$IV(a)=-\sum_{v=1}^V \frac{|D^v|}{|D|} \log_2 \frac{|D^v|}{|D|}$</p>
<h5 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h5><p>$Gini(D)=1-\sum_{k=1}^Np_k^2$</p>
<p>$Gini_a=\sum_{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)$</p>
<p>CART chooses lowest $Gini_a$.</p>
<h4 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h4><p>RF is a bagging algorithm (bootstrapping) which is based on decision tree. RF concludes some trees and each tree can give prediction. Every model in RF has similar bias and variance, </p>

$$
E[\frac{\sum X_i}{K}] = E[X_i] \\
\frac{Var(\sum X_i)}{K} \le Var(\frac{\sum X_i}{K}) \le Var(X_i) \\
Equation \ is \ valid \ when \ trees \ are \ independent \ or \ same.
$$


<p>We can find that RF can reduce variance, so RF is an effective way to solve overfitting problem. What’s more, the relavance of trees is associated with that ability, thus reducing the relavance is important. Fortunately, input data of each tree is subsampled in whole dataset, so we can try to choose different features with low overlap. Obviously, number of features is an important hyper-parameters to RF.</p>
<p>Important parameters: <strong>n_estimators</strong>; <strong>max_features</strong>; max_depth; min_samples_leaf; min_samples_split; max_leaf_nodes; min_samples_leaf</p>
<h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><p>AdaBoost is belonging to Boosting algorithm which literately combines weak learners to get the final strong learner. In Boosting, data are all given weights and misclassified data can get higher weights responding to higher importance. Meanwhile, those series of learners also have weights: low weights are given to high error learners, and high weights are given to low error leaners.</p>
<p>It’s time to talk about AdaBoost. It can be used in both classification and regression.</p>
<p>Assuming that is a binary classification problem with {-1, 1} as output and $k_{th}$ learner is denoted to $G_k(x)$.</p>

$$
e_k = P(G_k(x_i) \neq y_i) = \sum_{i=1}^m w_{ki}I(G_k(x_i) \neq y_i) \\
\alpha_k = \frac{1}{2} \log \frac{1-e_k}{e_k} \\ large \ \alpha \ is \ followed \ by \ small \ e \\
w_{k+1,i} = \frac{w_{k,i}}{Z_i} \exp (-\alpha_i G_k(x_i) y_i) \\
Z_k = \sum_{i=1}^m w_{k,i} \exp (-\alpha_i G_k(x_i)y_i) \\
G(x) = sign(\sum_{m=1}^K \alpha_m G_m(x))
$$


<p>If it is misclassification, $G_k(x_i)y_i=-1$, $w_{k+1,i} &gt; w_{k,i}$ which means that weights of misclassification get higher; otherwise,  $G_k(x_i)y_i=1$, $w_{k+1,i}&lt;w_{k,i}$.</p>
<p>Can we do regression by AdaBoost? Of course!</p>

$$
E_k = \max |y_i - G_k(x_i)|, i = 1,2,\cdots,m \\
e_{k,i} = \begin{cases}
\frac{|y_i - G_k(x_i)|}{E_k} & Linear \ Error \\
\frac{(y_i - G_k(x_i))^2}{E_k^2} & MSE \\
1 - \exp (\frac{-|y_i-G_k(x_i)|}{E_k}) & Exponential \ Error
\end{cases} \\
e_k = \sum_{i=1}^m w_{k,i} e_{k,i} \\
\alpha_k = \frac{e_k}{1-e_k} \\
w_{k+1,i} = \frac{w_{k,i}}{Z_k} \alpha_k^{1-e_{k,i}} \\
Z_k = \sum_{i=1}^m w_{k,i} \alpha_k^{1-e_{k,i}} \\
f(x)=\sum_{k=1}^K(\ln \frac{1}{\alpha_k})g(x) \\
g(x) \ is \ median \ of \ all \ \alpha_kG_k(x)
$$



<h4 id="Gradient-Boost-Decision-Tree-GBDT"><a href="#Gradient-Boost-Decision-Tree-GBDT" class="headerlink" title="Gradient Boost Decision Tree (GBDT)"></a>Gradient Boost Decision Tree (GBDT)</h4><p>In GBDT, we are using minus gradient of loss function to fit residual.</p>

$$
r_{m,i} = - [\frac{\partial L(y_i,f(x_i)}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)} \\
\Rightarrow R_{m,j} \\
T_{m,j}=argmin_T \sum_{x_i \in R_{m,j}} L(y_i,f_{m-1}(x_i)+T) \\
f_m(x) = f_{m-1}(x)+\sum_{j=1}^J c_{m,j}I(x \in R_{m,j})) \\
\hat{f(x)} = f_M(x)=f_0(x)+\sum_{m=1}^M \sum_{j=1}^J T_{m,j}I(x \in R_{m,j})
$$



<h4 id="XGBOOST"><a href="#XGBOOST" class="headerlink" title="XGBOOST"></a>XGBOOST</h4><p>$\Omega(f_t)= \gamma T + \frac{1}{2}\lambda \sum_{j=1}^Tw_j^2$</p>
<p>$T$ is number of leaf nodes; $w$ is leaf node scores.</p>

$$
\begin{align}
Obj^{(t)} &= \sum_{i=1}^n L(y_i, \hat{y_i}^{(t)})+\sum_{k=1}^t \Omega(f_k) \\
&= \sum_{i=1}^n L(y_i, \hat{y_i}^{(t-1)}+f_t(x_i)) + \sum_{k=1}^{t-1} \Omega(f_k) + \Omega(f_t) \\
&= \ \sum_{i=1}^n L(y_i, \hat{y_i}^{(t-1)}+f_t(x_i)) + \Omega(f_t) + Constant \\
\because & f(x_0+\triangle x) \approx f(x_0)+f'(x_0) \cdot \triangle x + \frac{f''(x_0)}{2} \cdot (\triangle x)^2 \\
\therefore &Obj^{(t)} \approx \sum_{i=1}^n [L(y_i, \hat{y_i}^{(t-1)})+g_if_t(x_i)+\frac{1}{2}h_if_t(x_i)^2] + \Omega(f_t) + Constant \\
\because &L(y_i, \hat{y_i}^{(t-1)}) \ is \ constant \\
\therefore & Obj^{(t)} = \sum_{i=1}^n [g_if_t(x_i)+\frac{1}{2}h_if_t(x_i)^2] + \Omega(f_t) + Constant \\
&g_i =\partial_{\hat{y}^{(t-1)}}L(y_i, \hat{y}^{(t-1)});h_i=\partial_{\hat{y}^{(t-1)}}^2L(y_i, \hat{y}^{(t-1)}) \\
\because &\Omega(f_t)= \gamma T + \frac{1}{2}\lambda \sum_{j=1}^Tw_j^2 \\
\therefore Obj^{(t)} &= \sum_{i=1}^n[g_i \cdot w_{q(x_i)}+\frac{1}{2}h_i \cdot w_{q(x_i)}^2]+\gamma T + \frac{1}{2}\lambda \sum_{j=1}^Tw_j^2 \\
&= \sum_{j=1}^T[(\sum_{i \in I_j}g_i)w_j+\frac{1}{2}(\sum_{i \in I_j}h_i+\lambda)w_j^2]+\gamma T \\
&= \sum_{j=1}^T[G_jw_j+\frac{1}{2}(H_j+\lambda)w_j^2]+\gamma T \\
\Rightarrow &w_j^*=-\frac{G_j}{H_j+\lambda} \\
\Rightarrow &Obj^*=-\frac{1}{2}\sum_{j=1}^T \frac{G_j^2}{H_j+\lambda}+\gamma T \ (scoring-function)
\end{align}
$$


<p>Scoring function measures tree structures, so the low the value, the better structure the better. Choosing best split point by scoring function to build CART.<br>$$<br>Gain = \frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gamma<br>$$<br>$Gain$ represents difference between single node $obj^<em>$ and two node $obj^</em>$. Traversing all features’ splitting points to find splitting point with max $Gain$. $G_L, G_R$ Is sum of first order gradient of left nodes and right nodes. $H_L, H_R$ is sum of second order gradient of left nodes and right nodes. $\lambda$ is regularization coefficient. $\gamma$ is difficulty of splitting node. $\lambda$ and $\gamma$ define complexity of trees.</p>
<p>If $\gamma$ is too large, $Gain$ is negative, which represents not splitting; The higher the $\gamma$, the more strict the obj’s dropping.</p>
<p>Difference with GBDT:</p>
<ul>
<li>XGBoost would consider complexity of CART in building process, but GBDT wouldn’t.</li>
<li>XGBoost fits last time loss function’s second order gradient, but GBDT just considers first order gradient.</li>
<li>XGBoost can compute parallelly (not in building tree, but in feature processing)<ul>
<li>xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</li>
</ul>
</li>
<li>XGBoost can deal with missing data</li>
<li>XGBoost can customize loss function if only it has second order gradient</li>
<li>XGBoost have column subsampling<ul>
<li>xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算.</li>
</ul>
</li>
</ul>
<p>Details of splitting algorithm can be seen in this <a href="https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&mid=2247485414&idx=1&sn=faa60d6b4653b9a73e6c5b1ae5f9fd22&chksm=fb39a2edcc4e2bfbe4d4b64c1d7c78b08ec6a4a07e03dd21c634add55bff1ced9693b75ecf88&token=309753865&lang=zh_CN&scene=21#wechat_redirect" target="_blank" rel="noopener">post</a>.</p>
<p>Details of tuning parameters can be seen in this <a href="https://sunjunee.github.io/2018/01/05/xgboost-tuning/" target="_blank" rel="noopener">post</a>.</p>
<h4 id="Light-GBM"><a href="#Light-GBM" class="headerlink" title="Light GBM"></a>Light GBM</h4><p> <a href="https://zhuanlan.zhihu.com/p/35155992" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35155992</a> </p>
<p>提升树是利用加模型与前向分布算法实现学习的优化过程，它有一些高效实现，如XGBoost, pGBRT，GBDT等。其中GBDT采用负梯度作为划分的指标（信息增益），XGBoost则利用到二阶导数。他们共同的不足是，计算信息增益需要扫描所有样本，从而找到最优划分点。在面对大量数据或者特征维度很高时，他们的效率和扩展性很难使人满意。微软开源的LightGBM（基于GBDT的）则很好的解决这些问题，它主要包含两个算法：</p>
<ul>
<li>GOSS（从减少样本角度）：排除大部分小梯度的样本，仅用剩下的样本计算信息增益。</li>
<li>EFB（从减少特征角度）：捆绑互斥特征，也就是他们很少同时取非零值（也就是用一个合成特征代替）。</li>
</ul>
<p>GBDT是基于决策树的集成算法，采用前向分布算法，在每次迭代中，都是通过负梯度拟合残差，从而学习一颗决策树，最耗时的步骤就是找最优划分点。一种流行的方法就是预排序，核心是在已经排好序的特征值上枚举所有可能的特征点。另一种改进则是直方图算法，他把连续特征值划分到k个桶中取，划分点则在这k个点中选取。k&lt;&lt;d，所以在内存消耗和训练速度都更佳，且在实际的数据集上表明，离散化的分裂点对最终的精度影响并不大，甚至会好一些。原因在于决策树本身就是一个弱学习器，采用Histogram算法会起到正则化的效果，有效地防止模型的过拟合。LightGBM也是基于直方图的。</p>
<p>为了减少训练数据，最直接的方法就是欠采样(down sample)，比如说过滤掉权重低于阈值的样本。SGD(随机梯度下降)采用的是在每轮迭代中选取随机子集进行训练弱分类器，AdaBoost则采用的是动态调整采样率。SGD可以应用到GBDT，但会影响精度，其他的则不能直接引入，因为GBDT中没有这种内在的权重。</p>
<p>为了减少特征，通常做的是PCA降维，但是这些方法都假设特征是冗余的，这并不一直正确。</p>
<p>一般大型数据集都是稀疏的，基于pre-sorted的GBDT可以通过忽略零值特征，从而减少训练代价。但是，基于histogram的则没有针对稀疏特性的优化方案，它只是计算累加值，不管你是0还是非0。所以，利用稀疏性的GBDT是很必要的。</p>
<p><strong>GOSS</strong></p>
<p>在AdaBoost中采用权重很好诠释了样本的重要性，GBDT没有这种权重，但是我们注意到每个数据样本的梯度可以被用来做采样的信息。也就是，如果一个样本的梯度小，那么表明这个样本已经训练好了，它的训练误差很小了，我们可以丢弃这些数据。当然，改变数据分布会造成模型的精度损失。GOSS则通过保存大梯度样本，随机选取小梯度样本，并为其弥补上一个常数权重。这样，GOSS更关注训练不足的样本，同时也不会改变原始数据太多。 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-1608d8b79f3d605e111878b715254d3e_hd.jpg" alt="GOSS"></p>
<p>先根据梯度对样本进行排序，选取 a * 100% 的top样本，再从剩余数据中随机选取 b * 100% 的样本，并乘以 的系数放大。</p>
<p>以前计算特征j在d值点的信息增益是这样的：</p>
<p> <img src="https://pic2.zhimg.com/80/v2-4b9a8ede817e0e68d889707b452fd921_hd.jpg" alt></p>
<p> 现在是这样的：</p>
<p> <img src="https://pic2.zhimg.com/80/v2-ea968fb24797e33e1ed60d9178814be5_hd.jpg" alt> </p>
<p>通过证明，近似误差很好，很贴近使用所有数据的模型。这也解释了LightGBM的 leaf-wise 生成策略。</p>
<p><strong>Leaf-wise (Best-first)的决策树生长策略</strong></p>
<p>大部分决策树的学习算法通过 level(depth)-wise 策略生长树，如下图一样：</p>
<p> <img src="https://pic2.zhimg.com/80/v2-255136baf2eaeec7841db3a2e45ca5a1_hd.jpg" alt="Level-wise"></p>
<p>LightGBM 通过 leaf-wise (best-first)策略来生长树。它将选取具有最大 delta loss 的叶节点来生长。 当生长相同的 #leaf，leaf-wise 算法可以比 level-wise 算法减少更多的损失。当 #data 较小的时候，leaf-wise 可能会造成过拟合。 所以，LightGBM 可以利用额外的参数 max_depth 来限制树的深度并避免过拟合（树的生长仍然通过 leaf-wise 策略）。</p>
<p> <img src="https://pic3.zhimg.com/80/v2-3f5b87c2c32efdfd33184be1e182b492_hd.jpg" alt="Leaf-wise"> </p>
<p><strong>EFB</strong></p>
<p>高维数据一般是稀疏的，可以设计一种损失最小的特征减少方法。并且，在稀疏特征空间中，许多特征都是互斥的，也就是它们几乎不同时取非0值。因此，我们可以安全的把这些互斥特征绑到一起形成一个特征，然后基于这些特征束构建直方图，这样又可以加速了。</p>
<p>有两个问题待解决，如何判断哪些特征该绑到一起，如何构建绑定。这是NP难的。</p>
<p>首先，转换到图着色问题。G=(V, E)，把关联矩阵G的每一行看成特征，从而得到|V|个特征，互斥束就图中颜色相同的顶点。图中点就是特征，边代表两个特征不互斥，也就是特征之间的冲突。如果算法允许小的冲突，可以得到更小的特征束数量，计算效率会更高。证明发现随机污染一小部分特征值，最多影响训练精度 ，是所有束中冲突最大的。通过选取合适的，我们可以很好的在效率和精度之间寻找平衡。</p>
<p>最后，排序就按照束的度来进行。当然，更一步优化是不够造图，直接<strong>根据非零值的数量排序</strong>，这个根据度排序很像，因为更多非0值意味着更高概率的冲突。更改了排序策略，可以避免重复。</p>
<p>第二个问题，合并特征，从而降低训练复杂度，关键是我们可以确保原先特征值可以从特征束中识别出来。因为直方图存储的是特征的离散桶，而不是连续值，我们可以通过把互斥特征放到不同桶，从而构造一个特征束。这可以通过添加偏移实现。如，假设我们有2个特征在一个特征束中，原先特征A的范围为[0,10)，特征B的范围为[0,20)，我们给特征B加上一个偏移10，它就变成[10,30)，这样我们就可以执行安全的合并了，用特征束[0,30)代替特征A和B。具体算法如下。</p>
<p> <img src="https://pic1.zhimg.com/80/v2-4d7875a088e184c694474be2bec26698_hd.jpg" alt="EFB algorithm"> </p>
<p>EFB算法可以把很多特征绑到一起，形成更少的稠密特征束，这样可以避免对0特征值的无用的计算。加速计算直方图还可以用一个表记录数据的非0值。 </p>
<hr>
<p> <a href="https://www.zhihu.com/question/51644470" target="_blank" rel="noopener">https://www.zhihu.com/question/51644470</a> </p>
<p>GBDT 虽然是个强力的模型，但却有着一个致命的缺陷，不能用类似 mini batch 的方式来训练，需要对数据进行无数次的遍历。如果想要速度，就需要把数据都预加载在内存中，但这样数据就会受限于内存的大小；如果想要训练更多的数据，就要使用外存版本的决策树算法。虽然外存算法也有较多优化，SSD 也在普及，但在频繁的 IO 下，速度还是比较慢的。</p>
<p>为了能让 GBDT 高效地用上更多的数据，我们把思路转向了分布式 GBDT， 然后就有了 LightGBM。设计的思路主要是两点，1. 单个机器在不牺牲速度的情况下，尽可能多地用上更多的数据；2.多机并行的时候，通信的代价尽可能地低，并且在计算上可以做到线性加速。</p>
<p>基于这两个需求，LightGBM 选择了基于 histogram 的决策树算法。相比于另一个主流的算法 pre-sorted（如 xgboost 中的 exact 算法），histogram 在内存消耗和计算代价上都有不少优势。</p>
<ul>
<li>Pre-sorted 算法需要的内存约是训练数据的两倍(2 * #data * #features<br>* 4Bytes)，它需要用32位浮点来保存 feature value，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于 histogram 算法，则只需要(#data* #features * 1Bytes)的内存消耗，仅为 pre-sorted算法的1/8。因为 histogram 算法仅需要存储 feature<br>bin value (离散化后的数值)，不需要原始的 feature value，也不用排序，而 bin value 用 uint8_t (256 bins) 的类型一般也就足够了。</li>
<li>在计算上的优势则主要体现在“数据分割”。决策树算法有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，Histogram 算法和 pre-sorted 算法在“寻找分割点”的代价是一样的，都是O(#feature*#data)。而在“数据分割”时，pre-sorted 算法需要O(#feature*#data)，而 histogram 算法是O(#data)。因为 pre-sorted 算法的每一列特征的顺序都不一样，分割的时候需要对每个特征单独进行一次分割。Histogram算法不需要排序，所有特征共享同一个索引表，分割的时候仅需对这个索引表操作一次就可以。（更新: <strong>这一点不完全正确，pre-sorted 与 level-wise 结合的时候，其实可以共用一个索引表(row_idx_to_tree_node_idx)。然后在寻找分割点的时候，同时操作同一层的节点，省去分割的步骤。但这样做的问题是会有非常多随机访问，有很大的cache miss，速度依然很慢。</strong>）</li>
<li>另一个计算上的优势则是大幅减少了计算分割点增益的次数。对于一个特征，pre-sorted 需要对每一个不同特征值都计算一次分割增益，而 histogram 只需要计算 #bin (histogram 的横轴的数量) 次。</li>
<li>最后，在数据并行的时候，用 histgoram 可以大幅降低通信代价。用 pre-sorted 算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst 在并行的时候也使用 histogram 进行通信。</li>
</ul>
<p>当然， histogram 算法也有缺点，它不能找到很精确的分割点，训练误差没有 pre-sorted 好。但从实验结果来看， histogram 算法在测试集的误差和 pre-sorted 算法差异并不是很大，甚至有时候效果更好。实际上可能决策树对于分割点的精确程度并不太敏感，而且较“粗”的分割点也自带正则化的效果。</p>
<p>在 histogram 算法之上， LightGBM 进行进一步的优化。首先它抛弃了大多数 GBDT 工具使用的按层生长<br>(level-wise) 的决策树生长策略，而使用了带有深度限制的按叶子生长 (leaf-wise) 算法。 level-wise 过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，不容易过拟合。但实际上level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大(一般也是数据量最大)的一个叶子，然后分裂，如此循环。因此同 level-wise 相比，在分裂次数相同的情况下，leaf-wise 可以降低更多的误差，得到更好的精度。leaf-wise 的缺点是可能会长出比较深的决策树，产生过拟合。因此 LightGBM 在leaf-wise 之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p>
<p>另一个比较巧妙的优化是 histogram 做差加速。一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的 k 个桶。利用这个方法，LightGBM 可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p>
<hr>
<p>非常赞的工作，实现了和XGBoost不一样的搜索策略，所以在算法效果上并不是完全一样。</p>
<p>- XGBoost在单机默认是exact greedy，搜索所有的可能分割点。分布式是dynamic histogram，每一轮迭代重新estimate 潜在split candidate。<br>- LightGBM和最近的FastBDT都采取了提前histogram binning再在bin好的数据上面进行搜索。在限定好candidate splits,<br>- 主要的速度提升似乎来自于两点。 一个是搜索的时候选取delta比较大的叶子扩展。第二个是pre-bin之后的histogram的求和用了一个非常巧妙的减法trick，省了一半的时间。</p>
<p>在算法和效果上面</p>
<p>最近比较多的工作都开始基于提前限定分割点的近似算法然后快速求histogram。 这一类算法的潜在问题是限制了分割点只能是一开始的定下来的潜在这些。不知道这一点对于实际应用的影响会有多大。理论上数据越多，树越深的时候，需要的潜在分割点越多，可能需要根据训练来动态更新潜在的分割点。</p>
<p>在算法上面采用delta比较大的扩展方向可以集中搜索提高比较重要的区域。一个潜在的问题是可能会忽略掉一些未来有潜力的节点。</p>
<p>当然这些讨论都和具体的应用场景有关。个人觉得exact greedy和histogram方法的还会共存一段时间。或许可以比较好的在系统上面对这两个一起支持</p>
<p>在系统上面</p>
<p>因为集中做针对叶子的分割，似乎会对于数据集的random access有一定的要求。如果不shuffle data的情况下可能会有cache 的问题。这个数据结构是一个有趣的问题</p>
<p>非常值得学习，机器学习系统优化是非常重要的方向。希望可以看到越来越多这样实际的工作</p>
<h4 id="Factorization-Machine-and-Field-Factorization-Machine"><a href="#Factorization-Machine-and-Field-Factorization-Machine" class="headerlink" title="Factorization Machine and Field Factorization Machine"></a>Factorization Machine and Field Factorization Machine</h4><h5 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h5><p>旨在解决稀疏数据下的特征组合问题，具有线性的计算复杂度；（矩阵分解方式处理参数，不仅能减少参数数量，还能处理由于稀疏性带来的参数不好训练的问题）一般的线性模型压根没有考虑特征间的关联(组合).</p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116022611357.png" alt="FM"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116022630055.png" alt></p>
<h5 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h5><p>通过引入field的概念，FFM把相同性质的特征归于同一个field。在FFM中，每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 vi,fj。因此，隐向量不仅与特征相关，也与field相关。如果隐向量的长度为 k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 $O(kn^2)$。</p>
<p> <img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/20170824140534619" alt="FFM"> </p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116023256527.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116023321114.png" alt></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191116023414278.png" alt="FFM using SGD"></p>
<p>FFM相对于FM加入了field的概念，每个特征的隐向量不再是只有一个，而是针对每个field学习一个独立的隐向量，防止互相影响。因此理论上来说，在理解业务的基础上，设计合理field之后的FFM模型应该是不会比FM差的。关键在于计算复杂度，FM通过合适的推导，训练/预测复杂度是线性的。而FFM的复杂度是二次方的。在工业界的业务中，如果FFM相对于FM提升不是很明显，一般还是选用FM模型，毕竟计算复杂度差的太多了。</p>
<h4 id="K-Means-and-EM"><a href="#K-Means-and-EM" class="headerlink" title="K-Means and EM"></a>K-Means and EM</h4><p>Choosing $k$ data points as cluster centers, then combining each data into those $k$ clusters by closest distance as metric. Finally, iteratively updating cluster centers by mean of all data of each cluster until no change of those centers.</p>
<p><a href="[https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm)">EM</a> is a powerful algorithm. </p>
<p>Details can be seen in these <a href="http://cs229.stanford.edu/notes/cs229-notes8.pdf" target="_blank" rel="noopener">post</a>, <a href="http://www.columbia.edu/~mh2078/MachineLearningORFE/EM_Algorithm.pdf" target="_blank" rel="noopener">post</a> and <a href="http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/" target="_blank" rel="noopener">post</a>.</p>
<h4 id="PCA-and-LDA"><a href="#PCA-and-LDA" class="headerlink" title="PCA and LDA"></a>PCA and LDA</h4><p><a href="http://www.svcl.ucsd.edu/courses/ece271B-F09/handouts/Dimensionality2.pdf" target="_blank" rel="noopener">http://www.svcl.ucsd.edu/courses/ece271B-F09/handouts/Dimensionality2.pdf</a></p>
<h4 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h4><h4 id="Spectral-Clustering"><a href="#Spectral-Clustering" class="headerlink" title="Spectral Clustering"></a>Spectral Clustering</h4><p><a href="https://github.com/zhangleiszu/machineLearning/blob/master/A%20Tutorial%20on%20Spectral%20Clustering.pdf" target="_blank" rel="noopener">https://github.com/zhangleiszu/machineLearning/blob/master/A%20Tutorial%20on%20Spectral%20Clustering.pdf</a></p>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><p><a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></p>
<h4 id="Characteristic"><a href="#Characteristic" class="headerlink" title="Characteristic"></a>Characteristic</h4><ul>
<li>Local feature </li>
<li>Sparse connectivity</li>
<li>Parameter sharing</li>
<li>Shift invariant </li>
</ul>
<h4 id="Different-Structures"><a href="#Different-Structures" class="headerlink" title="Different Structures"></a>Different Structures</h4><ul>
<li>Standard Convolution</li>
<li>Transposed Convolution (Deconvolution)</li>
<li>Dilated Convolution (Atrous Convolution)</li>
<li>Separable Convolution</li>
<li>Gated Convolution</li>
</ul>
<h4 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h4><h5 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h5><p>Advantages:</p>
<ul>
<li>increasing respective fields</li>
<li>shift invariant</li>
<li>reducing number of parameters and difficulty of optimization</li>
</ul>
<p>Pooling provides a sort of shift invariant, however it destroys information of position and space, etc. <a href="https://arxiv.org/pdf/1801.01450.pdf" target="_blank" rel="noopener">Quantifying Translation-Invariance in Convolutional Neural Networks</a> shows that CNN itself has no shift invariant which is learnt through data. </p>
<p>Another research from DeepMind, <a href="https://arxiv.org/pdf/1804.04438.pdf" target="_blank" rel="noopener">Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs</a>, shows that models can still get great performance without pooling. What’s more, they think that smoother of  parameters of CNN kernels can make shift more stable.</p>
<h5 id="Stochastic-Deep"><a href="#Stochastic-Deep" class="headerlink" title="Stochastic Deep"></a>Stochastic Deep</h5><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><h4 id="Basic-Structure"><a href="#Basic-Structure" class="headerlink" title="Basic Structure"></a>Basic Structure</h4><p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191115220219342.png" alt="RNN"><br>$$<br>\Rightarrow a^{(t)} = W \cdot [h^{(t-1)};x^{(t)}]+b \<br>\Rightarrow h^{(t)} = f(a^{(t)}) \<br>\Rightarrow h^{(t)}=f(h^{(t-1)},x^{(t)};\theta) \<br>$$<br>$Tanh$ is always the activation function.</p>
<p><a href="https://www.zhihu.com/question/61265076" target="_blank" rel="noopener">Why do we use tanh as activation function but ReLU?</a></p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191115220304740.png" alt="LSTM"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191118002139210.png" alt="forget gate"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191118002146556.png" alt="input gate"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191118002155566.png" alt="cell status"></p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191118002203027.png" alt="output gate and hidden status"></p>
<h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p><a href="https://medium.com/mlrecipies/deep-learning-basics-gated-recurrent-unit-gru-1d8e9fae7280" target="_blank" rel="noopener">https://medium.com/mlrecipies/deep-learning-basics-gated-recurrent-unit-gru-1d8e9fae7280</a></p>
<p>It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. </p>
<p><img src="/2019/12/11/Study-Notes-of-Machine-Learning-V1/image-20191115220329260.png" alt="GRU"></p>
<h4 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h4><p><a href="https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45" target="_blank" rel="noopener">https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>On the Number of Linear Regions of Deep Neural Networks</title>
    <url>/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h3><p>使用ReLU等非线性单元的神经网络相当于一个分片线性函数，线性区域越多，神经网络的非线性就越强，网络的效果可能就更好。这篇文章讨论了在神经元总数一样的情况下，增加网络的深度可以产生更多的线性区域。文章中使用折纸类比了这个过程。</p><img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209181524633.png" title="李宏毅Deep Structure PPT"><p>以ReLU为例，我们知道ReLU单元$y=ReLU(Wx+b)$会在输入空间中产生一个超平面$Wx+b=0$,把输入空间分成两部分，一部分的空间输出值为常数0，另一个空间的输出为$y=Wx+b$。可以看到一个分片线性函数会产生两个线性区域。那么如果输入空间是二维，就像一张纸沿着$Wx+b=0$折一下，再打开，会产生两个线性区域。</p><p>对于一个具有两个ReLU单元的单隐藏层神经网络，$y_1=ReLU(W_1x+b_1)$和$y_2=ReLU(W_2x+b_2)$，输出为$y=y_1+y_2$。那么这个神经网络就有四个线性区域，每个区域的输出值为0、$W_1x+b_1$、$W_2x+b_2$和$(W_1+W_2)x+(b_1+b_2)$。这就像一张纸，先沿着$W_1x+b_1=0$折一下，打开，再沿着$W_2x+b_2=0$折一下，会产生四个区域。所以如果只有一个隐藏层，单纯地增加神经元的个数，相当于重复上述操作，不断的沿着一条线折一下，再打开。对于一张二维的纸而言，折叠N此所产生的线性区域不超过$\frac{N^2+N}{2}+1$.</p><a id="more"></a>
                        



<p>对于两个隐藏层的神经网络。第二层的一个ReLU单元会在第二层的输入空间（第一层的输出值域）上形成一个超平面，并将第一层的值域分成两个区域。而我们注意到，第一层可能会把不同的输入映射到相同的输出值，因此在第一层的值域上又多一个区域，就可能再输入空间上多出好几个区域。这就像拿一张纸，折几下，折出几个区域，然后不打开，再折一下。那么最后折的这一下，就会在之前折出的多个区域中新增一个区域。这就是增加层数带来的效果。对于更深层的网络，就像拿一张纸，一直折N次，折到最后才打开，那么这些折痕最多可以把纸分割成$2^N$个区域。</p>
<h3 id="1-Introduction-amp-Conclusion"><a href="#1-Introduction-amp-Conclusion" class="headerlink" title="1. Introduction &amp; Conclusion"></a>1. Introduction &amp; Conclusion</h3><p>这篇文章研究了深度前馈神经网络可根据它们的线性区域数计算函数的复杂性；讨论了深层模型的每一层都能够识别其输入片段，使得层与层的组合能够识别指数数量的输入区域。这导致指数地复制在更高层中计算的函数的复杂性。深度模型以这种方式计算的函数是复杂的，但是它们仍然具有由复制引起的intrinsic rigidity，这可能有助于深度模型比浅模型更好地泛化到看不见的样本。线性区域的结构取决于单元的类型，例如hyperplane arrangements for shallow rectifier和Voronoi diagrams for shallow maxout networks。在maxout和rectifier网络中，随着深度增加区域数量都指数地增长。给定网络的参数空间被划分为目标函数具有相应线性区域的区域。</p>
<p>在许多隐藏层的渐近极限中，尽管使用相同数量的计算单元，深层网络能够将它们的输入空间分成比浅层网络指数地更线性的响应区域。这篇文章描述了那些模型的中间层如何将它们的几个输入映射到同一个输出。以这种方式计算的函数的分层组合经常随着层数的增加而指数地重复使用低级计算。这一关键属性使深层网络能够计算高度复杂和结构化的函数。通过估计可由两种重要类型的分段线性网络（rectifier units和maxout units）计算的函数的线性区域的数量来支持这个想法。</p>
<p>给定模型可以计算的函数的线性区域的数量是模型灵活性的度量。如图1所示，比较了相同隐藏神经元数量的单层和双层网络学到的决策边界，体现了深度的优势；深层模型更精确地捕捉到所需的边界，用大量的线性pieces来逼近它。深层网络能够通过将输入邻域映射到中间隐藏层的一个公共输出来识别指数数量的输入邻域。对该中间层的激活的计算被复制多次，在每个被识别的邻域中复制一次。这允许网络计算非常复杂的函数，即使它们是用相对较少的参数定义的。参数的数量是可由网络计算的函数的维度的上限，而少量参数意味着可计算函数具有低维度。深度前馈分段线性网络可计算的一组函数即使维度很低，但通过在层与层之间重复使用和组合特征，实现了指数复杂性。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191208183425173.png">

<h3 id="2-Feedforward-Neural-Networks-and-their-Compositional-Properties"><a href="#2-Feedforward-Neural-Networks-and-their-Compositional-Properties" class="headerlink" title="2.Feedforward Neural Networks and their Compositional Properties"></a>2.Feedforward Neural Networks and their Compositional Properties</h3><p>本节讨论了深度前馈网络通过使用相对较少的计算单元来重新映射其输入空间以创建复杂对称性的能力。分析了深度模型的每一层都能够将其输入的不同区域映射到一个公共输出。这导致了一种复合结构，其中在给定层上产生相同输出的所有输入区域中，有效地复制了较高层上的计算。在输入空间上复制计算的能力随网络层的数量呈指数增长。</p>
<h4 id="2-1-Shallow-Neural-Networks"><a href="#2-1-Shallow-Neural-Networks" class="headerlink" title="2.1 Shallow Neural Networks"></a>2.1 Shallow Neural Networks</h4>

根据输入的不同，Rectifier units有两种行为，等于0或者线性。这两个行为之间的边界由超平面给出，来自rectifier层中所有单元的所有超平面的集合形成一个hyperplane arrangement。arrangement中的超平面将输入空间分为几个区域。arrangement的区域数量可以根据arrangement的特征函数给出。在$R^{n_0}$中一个$n_1$的arrangement有最多$\sum_{j=0}^{n_0} {{n_1} \choose j}$个区域。当且仅当超平面处于一般位置时，才能实现这个数量的区域。这意味着由shallow rectifier network（$n_0$的输入和$n_1$的隐藏单元）计算的函数的线性区域的最大数量是$\sum_{j=0}^{n_0} {n_1 \choose j}$。



<h4 id="2-2-Deep-Neural-Networks"><a href="#2-2-Deep-Neural-Networks" class="headerlink" title="2.2 Deep Neural Networks"></a>2.2 Deep Neural Networks</h4><img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209001503997.png">

<p>由前馈网络的L层对L-1层的一组激活进行的计算可有效地对导致L-1层相同激活的所有输入空间区域进行。可以选择给定层的输入权重和偏差，使得计算的函数在输入空间中具有最大数量的preimages的前一层的那些激活值上表现出最有趣的行为，从而在输入空间中多次重复有趣的计算和生成complicated-looking的函数。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209003254040.png">

<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209003328371.png">

<p>构造具有许多线性区域的函数的想法是使用前L-1个隐藏层来标识许多输入空间邻域，并将它们全部映射到L-1隐层的激活邻域$P^L$，每个激活邻域$P^L$都属于一个不同的最后一个隐藏层的线性区域。</p>
<h4 id="2-34-Identification-of-Inputs-as-Space-Foldings"><a href="#2-34-Identification-of-Inputs-as-Space-Foldings" class="headerlink" title="2.34 Identification of Inputs as Space Foldings"></a>2.34 Identification of Inputs as Space Foldings</h4><img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209003729020.png">

<p>识别两个子集$S$和$S’$的映射$F$可以看成是折叠它domain的一种算子，折叠后$S$和$S’$被映射到相同的输出。如图2所示，absolute value function折叠它自己的domain两次（两个坐标轴各一次）。这种折叠识别了二维欧几里德空间的四个象限。通过组成这样的操作，相同类型的映射可以再次应用于输出，以便重新折叠之前的第一次折叠。深层神经网络的每个隐藏层都和一种折叠算子相关。每个隐藏层折叠前一层的激活空间。反过来，深层神经网络从第一层开始有效地递归折叠其输入空间。这种递归折叠的结果是，在最终折叠空间上计算的任何函数都将应用于由对应于连续折叠的映射所识别的所有的折叠子集。这意味着在深度模型中，最后一层的图像空间的任何划分都被复制到由一连串折叠识别的所有输入空间区域中。</p>
<p>空间折叠不限于沿坐标轴折叠，也不必保留长度。相反，空间被折叠是根据输入权重$W$和偏置$b$中编码的方向和偏移以及在每个隐藏层使用的非线性激活函数。这意味着所识别的输入空间区域的大小和方向可以彼此不同。在激活函数不是分段线性的情况下，折叠操作可能更加复杂。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209130708933.png">

<h3 id="3-Deep-Rectifier-Network"><a href="#3-Deep-Rectifier-Network" class="headerlink" title="3.Deep Rectifier Network"></a>3.Deep Rectifier Network</h3><img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209133906134.png">

<h4 id="3-1-Illustration-of-the-Construction"><a href="#3-1-Illustration-of-the-Construction" class="headerlink" title="3.1 Illustration of the Construction"></a>3.1 Illustration of the Construction</h4><p>考虑一层网络有$n$个rectifiers，$n_0$个输入变量，其中$n \geq n_0$。将rectifier单元集划分为基数为$p=[n / n_0]$的$n_0$个(非重叠)子集，忽略多余单元。考虑第$j$个子集中的单元。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209140301680.png">

<p>$\tilde h$是由$h$通过与线性函数组合产生的。这个线性函数可以有效地被下一层的预激活函数吸收。因此，我们可以将$\tilde h$视为由当前层计算的函数。作为此rectifier层的单位超立方体输出的函数，由较深层进行的计算将复制到$p^{n_0}$个已识别输入空间超立方体的每一个上。</p>
<h4 id="3-2-Formal-Result"><a href="#3-2-Formal-Result" class="headerlink" title="3.2 Formal Result"></a>3.2 Formal Result</h4><p>可以将上面所描述的construction泛化为一个深层rectifier网络，有$n_0$的输入和$L$层宽度为$n_i$的隐藏层，对于所有$i \in [L]$，$n_i \geq n_0$。那么这个深层rectifier网络的线性区域的最大数量的下限为：</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209153956151.png">

<p>下一个推论给出这些边界的渐近行为的表达式。假设对于所有$i \geq 1$都有$n_0=\Omega (1)$和$n_i=n_0$，一个有$Ln$个隐藏单元的单层网络的区域数量表现为$\Omega (L^{n_0}n^{n_0})$。但是，对于一个深度网络，</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209154657346.png">

<p>因此，深层模型的线性区域数量呈指数增长(in $L$)，以及呈多项式增长(in $n$)，这比具有$nL$个隐藏单元的浅层模型的线性区域快得多。结果表明，即使$L$和$n$较小，深的rectifier模型也比浅的rectifier模型能够产生更多的线性区域。</p>
<h3 id="4-Deep-Maxout-Networks"><a href="#4-Deep-Maxout-Networks" class="headerlink" title="4.Deep Maxout Networks"></a>4.Deep Maxout Networks</h3><img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209155554775.png">

<p>由于两个凸函数的最大值为凸，因此maxout单元和maxout层将计算凸函数。函数集合的最大值被称为<em>upper envelope</em>。一个maxout单元线性区域的最大数量等于它的rank(上式中的k)。</p>
<p>maxout层的线性区域是各个maxout单元的线性区域的交集。为了获得该层的线性区域的数量，需要描述每个maxout单元的线性区域的结构，并研究它们可能的交集。Voronoi图可以提升到线性函数的upper envelopes，因此它们描述了由maxout单元生成的输入空间分区。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209161748533.png">

<p>可以通过一个具有两倍数量单元的rectifier层来模拟一个rank-2 maxout层。一个有$L-1$个宽度$n=n_0$的隐藏层的rank-2 maxout网络可以识别出$2^{n_0(L-1)}$个输入空间区域。反过来看，它可以计算有$2^{n_0(L-1)}2^{n_0}=2^{n_0L}$个线性区域的函数。对于rank-k，一个rank-k maxout单元可以从它的输入域识别k个cones，每个cone都与一个对应线性方程$f_i$的梯度$W_i$的positive half-ray ${rW_i \in R^n: r \in R_+ }$相邻。</p>
<img src="/2019/12/09/On-the-Number-of-Linear-Regions-of-Deep-Neural-Networks/image-20191209162932406.png">

<p>所以深层maxout网络可以计算具有多个线性区域的函数，这些线性区域随层数成指数增长，并且比具有相同数量单元的浅层模型的最大区域数更快地成指数增长。与rectifier模型相似，该指数行为也可以根据网络参数的数量来确定。尽管可以由maxout层计算的某些函数也可以由rectifier层计算，但是从最后一节开始的rectifier构造会出现maxout网络无法计算的函数。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://www.zhihu.com/question/62705160/answer/201377484" target="_blank" rel="noopener">https://www.zhihu.com/question/62705160/answer/201377484</a></p>
<p>[2] <a href="https://arxiv.org/pdf/1402.1869.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1402.1869.pdf</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么神经网络越深越好</title>
    <url>/2019/11/24/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B6%8A%E6%B7%B1%E8%B6%8A%E5%A5%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近在StackExchange上看到的一个帖子，<a href="https://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network-and-w" target="_blank" rel="noopener">What is the difference between a neural network and a deep neural network, and why do the deep ones work better?</a>，讨论的是“深度”对于神经网络的影响。从下面的图片可以看到ImageNet中的冠军模型也越来越深。</p><img src="/2019/11/24/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B6%8A%E6%B7%B1%E8%B6%8A%E5%A5%BD/20191124-1.png" width="80%" height="80%" title="ImageNet" alt="ImageNet"><p>在Deep Learning那本书中，我们也能看到一样的结果。</p><img src="/2019/11/24/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B6%8A%E6%B7%B1%E8%B6%8A%E5%A5%BD/20191124-2.png" width="80%" height="80%" title="Book: Deep Learning" alt="Book: Deep Learning"><p>为什么网络越深模型的表现越好呢？下面是不同角度对这个问题的回答。</p><p>在知乎的帖子<a href="https://www.zhihu.com/question/313633835" target="_blank" rel="noopener">网络深度对深度学习模型性能有什么影响？</a>中，答主言有三从两个方面解释了<u>为什么加深可以提升性能</u>：<strong>1.更好的拟合特征，更强大的表达能力。更深的模型，意味着更好的非线性表达能力，可以学习更加复杂的变换，从而可以拟合更加复杂的特征输入。2.网络更深，每一层要做的事情也更加简单了，可以更好地进行逐层学习。</strong></p><a id="more"></a>







<p>同时他也提到了<u>模型变深后带来的两个问题</u>：<strong>1.加深带来的优化问题。深层网络带来的梯度不稳定，网络退化的问题始终都是存在的，可以缓解，没法消除。这就有可能出现网络加深，性能反而开始下降。2.网络加深带来的饱和。随着深度的增加，模型的提升效果逐渐饱和。除此之外，模型加深还可能出现的一些问题是导致某些浅层的学习能力下降，限制了深层网络的学习，这也是跳层连接等结构能够发挥作用的很重要的因素。</strong>模型变深怎么也绕不开ResNet，最近看了很多关于ResNet的文章，对它有了一些新的认识，后面会写一篇ResNet的文章分享。</p>
<p>另一篇知乎的帖子<a href="https://www.zhihu.com/question/62705160/answer/201377484" target="_blank" rel="noopener">如何形象的解释深度学习神经网络需要更深而非更广？</a>，一个答主引用Yoshua Begio的paper-<a href="https://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf" target="_blank" rel="noopener">On the Number of Linear Regions of Deep Neural Networks</a>的观点（前面的那篇帖子中也提到了这个，后面会写一篇这篇paper的总结）。主要的观点是：<strong>使用ReLU、MaxOut等非线性单元的神经网络在数学上相当于一个分片线性函数，线性区域(linear region)越多，神经网络的非线性就越强，也就更有可能在实际任务中取得好的效果。</strong></p>
<p>另一个角度的解释是</p>
<blockquote>
<p>通常来说，卷积核的大小通常为3*3或者5*5，相对于图片几百乘几百的大小来说，那么小的卷积核一次只能覆盖很小的区域，所以浅层小卷积核只能探测到诸如边或者角这种比较低层次的特征。<strong>随着网络深度的增加，卷积核的有效感受野越来越大，也就意味着高层的卷积核能够覆盖更大尺度上的特征</strong>。也可以认为高层的卷积核将低层卷积核学习到的特征进行了组合。那么问题来了，增加宽度我们说是增加了某一层卷积核的个数，也就意味着探测到的低层次特征理论上变多了。如果仅仅是增加宽度而深度不够，那么最后输出的高层特征仅仅组合了较少的低层特征，比如低层的卷积核探测到了眼睛鼻子和尾巴，第四层可以把眼睛和鼻子组合起来，但是尾巴距离眼睛比较远，可能需要第六层的卷积核的有效感受野才能同时探测到尾巴和眼睛，所以说如果现在网络只有四层，很有可能不能结合距离较远的两个特征。所以说深度很重要，因为更深的卷积核的有效感受野越大，能够组合的低层特征越多。图像分类任务最终的分类依据应该是丰富的低层特征组合而不是分散的低层特征。</p>
<p>作者：Terence Wu</p>
</blockquote>
<p>综上所述，模型越来越深背后的理论和实践解释：</p>
<ol>
<li>“a naive answer is that because they work better”；</li>
<li>更深的模型可以更好的拟合特征；</li>
<li>网络更深，每一层要做的事情也更加简单了，可以更好地进行逐层学习；</li>
<li>使用非线性单元（RELU、Maxout等）的神经网络，网络越深，特征空间被分割得到的线性区域越多，模型的表现越好。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
</search>
